2023-08-26 11:01:38,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 11:01:38,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 11:01:38,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 11:01:38,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 11:01:46,329:INFO:PyCaret ClassificationExperiment
2023-08-26 11:01:46,329:INFO:Logging name: clf-default-name
2023-08-26 11:01:46,330:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 11:01:46,330:INFO:version 3.0.4
2023-08-26 11:01:46,330:INFO:Initializing setup()
2023-08-26 11:01:46,331:INFO:self.USI: 5cab
2023-08-26 11:01:46,331:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'gpu_param', 'idx', 'html_param', 'X', 'memory', 'exp_name_log', 'is_multiclass', 'X_train', 'target_param', 'fold_groups_param', '_ml_usecase', 'data', 'gpu_n_jobs_param', '_available_plots', 'logging_param', 'pipeline', 'exp_id', 'n_jobs_param', 'y', 'seed', 'USI', 'fold_generator', 'fix_imbalance', 'X_test'}
2023-08-26 11:01:46,331:INFO:Checking environment
2023-08-26 11:01:46,331:INFO:python_version: 3.10.2
2023-08-26 11:01:46,331:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 11:01:46,332:INFO:machine: AMD64
2023-08-26 11:01:46,332:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 11:01:46,336:INFO:Memory: svmem(total=12729561088, available=4447207424, percent=65.1, used=8282353664, free=4447207424)
2023-08-26 11:01:46,337:INFO:Physical Core: 2
2023-08-26 11:01:46,337:INFO:Logical Core: 4
2023-08-26 11:01:46,337:INFO:Checking libraries
2023-08-26 11:01:46,337:INFO:System:
2023-08-26 11:01:46,338:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 11:01:46,338:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 11:01:46,338:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 11:01:46,338:INFO:PyCaret required dependencies:
2023-08-26 11:01:46,449:INFO:                 pip: 23.2.1
2023-08-26 11:01:46,450:INFO:          setuptools: 58.1.0
2023-08-26 11:01:46,450:INFO:             pycaret: 3.0.4
2023-08-26 11:01:46,450:INFO:             IPython: 8.14.0
2023-08-26 11:01:46,451:INFO:          ipywidgets: 8.1.0
2023-08-26 11:01:46,451:INFO:                tqdm: 4.66.1
2023-08-26 11:01:46,451:INFO:               numpy: 1.23.5
2023-08-26 11:01:46,451:INFO:              pandas: 1.5.3
2023-08-26 11:01:46,451:INFO:              jinja2: 3.1.2
2023-08-26 11:01:46,452:INFO:               scipy: 1.11.2
2023-08-26 11:01:46,452:INFO:              joblib: 1.3.2
2023-08-26 11:01:46,452:INFO:             sklearn: 1.2.2
2023-08-26 11:01:46,452:INFO:                pyod: 1.1.0
2023-08-26 11:01:46,452:INFO:            imblearn: 0.11.0
2023-08-26 11:01:46,452:INFO:   category_encoders: 2.6.2
2023-08-26 11:01:46,453:INFO:            lightgbm: 4.0.0
2023-08-26 11:01:46,453:INFO:               numba: 0.57.1
2023-08-26 11:01:46,453:INFO:            requests: 2.31.0
2023-08-26 11:01:46,453:INFO:          matplotlib: 3.7.2
2023-08-26 11:01:46,453:INFO:          scikitplot: 0.3.7
2023-08-26 11:01:46,453:INFO:         yellowbrick: 1.5
2023-08-26 11:01:46,454:INFO:              plotly: 5.16.1
2023-08-26 11:01:46,454:INFO:    plotly-resampler: Not installed
2023-08-26 11:01:46,454:INFO:             kaleido: 0.2.1
2023-08-26 11:01:46,454:INFO:           schemdraw: 0.15
2023-08-26 11:01:46,454:INFO:         statsmodels: 0.14.0
2023-08-26 11:01:46,455:INFO:              sktime: 0.22.0
2023-08-26 11:01:46,455:INFO:               tbats: 1.1.3
2023-08-26 11:01:46,455:INFO:            pmdarima: 2.0.3
2023-08-26 11:01:46,455:INFO:              psutil: 5.9.5
2023-08-26 11:01:46,456:INFO:          markupsafe: 2.1.3
2023-08-26 11:01:46,456:INFO:             pickle5: Not installed
2023-08-26 11:01:46,456:INFO:         cloudpickle: 2.2.1
2023-08-26 11:01:46,456:INFO:         deprecation: 2.1.0
2023-08-26 11:01:46,456:INFO:              xxhash: 3.3.0
2023-08-26 11:01:46,456:INFO:           wurlitzer: Not installed
2023-08-26 11:01:46,456:INFO:PyCaret optional dependencies:
2023-08-26 11:01:46,526:INFO:                shap: Not installed
2023-08-26 11:01:46,526:INFO:           interpret: Not installed
2023-08-26 11:01:46,526:INFO:                umap: Not installed
2023-08-26 11:01:46,527:INFO:    pandas_profiling: Not installed
2023-08-26 11:01:46,527:INFO:  explainerdashboard: Not installed
2023-08-26 11:01:46,528:INFO:             autoviz: Not installed
2023-08-26 11:01:46,528:INFO:           fairlearn: Not installed
2023-08-26 11:01:46,528:INFO:          deepchecks: Not installed
2023-08-26 11:01:46,528:INFO:             xgboost: 1.7.6
2023-08-26 11:01:46,529:INFO:            catboost: Not installed
2023-08-26 11:01:46,529:INFO:              kmodes: Not installed
2023-08-26 11:01:46,529:INFO:             mlxtend: Not installed
2023-08-26 11:01:46,529:INFO:       statsforecast: Not installed
2023-08-26 11:01:46,529:INFO:        tune_sklearn: Not installed
2023-08-26 11:01:46,529:INFO:                 ray: Not installed
2023-08-26 11:01:46,530:INFO:            hyperopt: Not installed
2023-08-26 11:01:46,537:INFO:              optuna: Not installed
2023-08-26 11:01:46,537:INFO:               skopt: Not installed
2023-08-26 11:01:46,537:INFO:              mlflow: Not installed
2023-08-26 11:01:46,537:INFO:              gradio: Not installed
2023-08-26 11:01:46,539:INFO:             fastapi: Not installed
2023-08-26 11:01:46,540:INFO:             uvicorn: Not installed
2023-08-26 11:01:46,540:INFO:              m2cgen: Not installed
2023-08-26 11:01:46,540:INFO:           evidently: Not installed
2023-08-26 11:01:46,540:INFO:               fugue: Not installed
2023-08-26 11:01:46,540:INFO:           streamlit: Not installed
2023-08-26 11:01:46,541:INFO:             prophet: Not installed
2023-08-26 11:01:46,541:INFO:None
2023-08-26 11:01:46,541:INFO:Set up data.
2023-08-26 11:02:05,367:INFO:PyCaret ClassificationExperiment
2023-08-26 11:02:05,368:INFO:Logging name: clf-default-name
2023-08-26 11:02:05,368:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 11:02:05,368:INFO:version 3.0.4
2023-08-26 11:02:05,368:INFO:Initializing setup()
2023-08-26 11:02:05,368:INFO:self.USI: d7af
2023-08-26 11:02:05,369:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'gpu_param', 'idx', 'html_param', 'X', 'memory', 'exp_name_log', 'is_multiclass', 'X_train', 'target_param', 'fold_groups_param', '_ml_usecase', 'data', 'gpu_n_jobs_param', '_available_plots', 'logging_param', 'pipeline', 'exp_id', 'n_jobs_param', 'y', 'seed', 'USI', 'fold_generator', 'fix_imbalance', 'X_test'}
2023-08-26 11:02:05,369:INFO:Checking environment
2023-08-26 11:02:05,369:INFO:python_version: 3.10.2
2023-08-26 11:02:05,369:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 11:02:05,370:INFO:machine: AMD64
2023-08-26 11:02:05,370:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 11:02:05,375:INFO:Memory: svmem(total=12729561088, available=4379877376, percent=65.6, used=8349683712, free=4379877376)
2023-08-26 11:02:05,375:INFO:Physical Core: 2
2023-08-26 11:02:05,375:INFO:Logical Core: 4
2023-08-26 11:02:05,375:INFO:Checking libraries
2023-08-26 11:02:05,376:INFO:System:
2023-08-26 11:02:05,376:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 11:02:05,376:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 11:02:05,376:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 11:02:05,376:INFO:PyCaret required dependencies:
2023-08-26 11:02:05,377:INFO:                 pip: 23.2.1
2023-08-26 11:02:05,377:INFO:          setuptools: 58.1.0
2023-08-26 11:02:05,378:INFO:             pycaret: 3.0.4
2023-08-26 11:02:05,378:INFO:             IPython: 8.14.0
2023-08-26 11:02:05,378:INFO:          ipywidgets: 8.1.0
2023-08-26 11:02:05,378:INFO:                tqdm: 4.66.1
2023-08-26 11:02:05,378:INFO:               numpy: 1.23.5
2023-08-26 11:02:05,379:INFO:              pandas: 1.5.3
2023-08-26 11:02:05,379:INFO:              jinja2: 3.1.2
2023-08-26 11:02:05,379:INFO:               scipy: 1.11.2
2023-08-26 11:02:05,379:INFO:              joblib: 1.3.2
2023-08-26 11:02:05,380:INFO:             sklearn: 1.2.2
2023-08-26 11:02:05,380:INFO:                pyod: 1.1.0
2023-08-26 11:02:05,380:INFO:            imblearn: 0.11.0
2023-08-26 11:02:05,380:INFO:   category_encoders: 2.6.2
2023-08-26 11:02:05,380:INFO:            lightgbm: 4.0.0
2023-08-26 11:02:05,381:INFO:               numba: 0.57.1
2023-08-26 11:02:05,381:INFO:            requests: 2.31.0
2023-08-26 11:02:05,381:INFO:          matplotlib: 3.7.2
2023-08-26 11:02:05,381:INFO:          scikitplot: 0.3.7
2023-08-26 11:02:05,381:INFO:         yellowbrick: 1.5
2023-08-26 11:02:05,382:INFO:              plotly: 5.16.1
2023-08-26 11:02:05,382:INFO:    plotly-resampler: Not installed
2023-08-26 11:02:05,382:INFO:             kaleido: 0.2.1
2023-08-26 11:02:05,382:INFO:           schemdraw: 0.15
2023-08-26 11:02:05,382:INFO:         statsmodels: 0.14.0
2023-08-26 11:02:05,383:INFO:              sktime: 0.22.0
2023-08-26 11:02:05,383:INFO:               tbats: 1.1.3
2023-08-26 11:02:05,383:INFO:            pmdarima: 2.0.3
2023-08-26 11:02:05,383:INFO:              psutil: 5.9.5
2023-08-26 11:02:05,383:INFO:          markupsafe: 2.1.3
2023-08-26 11:02:05,384:INFO:             pickle5: Not installed
2023-08-26 11:02:05,384:INFO:         cloudpickle: 2.2.1
2023-08-26 11:02:05,384:INFO:         deprecation: 2.1.0
2023-08-26 11:02:05,384:INFO:              xxhash: 3.3.0
2023-08-26 11:02:05,384:INFO:           wurlitzer: Not installed
2023-08-26 11:02:05,385:INFO:PyCaret optional dependencies:
2023-08-26 11:02:05,385:INFO:                shap: Not installed
2023-08-26 11:02:05,385:INFO:           interpret: Not installed
2023-08-26 11:02:05,385:INFO:                umap: Not installed
2023-08-26 11:02:05,386:INFO:    pandas_profiling: Not installed
2023-08-26 11:02:05,386:INFO:  explainerdashboard: Not installed
2023-08-26 11:02:05,386:INFO:             autoviz: Not installed
2023-08-26 11:02:05,386:INFO:           fairlearn: Not installed
2023-08-26 11:02:05,387:INFO:          deepchecks: Not installed
2023-08-26 11:02:05,387:INFO:             xgboost: 1.7.6
2023-08-26 11:02:05,388:INFO:            catboost: Not installed
2023-08-26 11:02:05,388:INFO:              kmodes: Not installed
2023-08-26 11:02:05,388:INFO:             mlxtend: Not installed
2023-08-26 11:02:05,389:INFO:       statsforecast: Not installed
2023-08-26 11:02:05,389:INFO:        tune_sklearn: Not installed
2023-08-26 11:02:05,389:INFO:                 ray: Not installed
2023-08-26 11:02:05,390:INFO:            hyperopt: Not installed
2023-08-26 11:02:05,390:INFO:              optuna: Not installed
2023-08-26 11:02:05,390:INFO:               skopt: Not installed
2023-08-26 11:02:05,390:INFO:              mlflow: Not installed
2023-08-26 11:02:05,391:INFO:              gradio: Not installed
2023-08-26 11:02:05,391:INFO:             fastapi: Not installed
2023-08-26 11:02:05,391:INFO:             uvicorn: Not installed
2023-08-26 11:02:05,391:INFO:              m2cgen: Not installed
2023-08-26 11:02:05,392:INFO:           evidently: Not installed
2023-08-26 11:02:05,392:INFO:               fugue: Not installed
2023-08-26 11:02:05,392:INFO:           streamlit: Not installed
2023-08-26 11:02:05,392:INFO:             prophet: Not installed
2023-08-26 11:02:05,393:INFO:None
2023-08-26 11:02:05,393:INFO:Set up data.
2023-08-26 12:05:41,682:INFO:PyCaret ClassificationExperiment
2023-08-26 12:05:41,683:INFO:Logging name: clf-default-name
2023-08-26 12:05:41,683:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 12:05:41,683:INFO:version 3.0.4
2023-08-26 12:05:41,683:INFO:Initializing setup()
2023-08-26 12:05:41,684:INFO:self.USI: 6ef4
2023-08-26 12:05:41,684:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'gpu_param', 'idx', 'html_param', 'X', 'memory', 'exp_name_log', 'is_multiclass', 'X_train', 'target_param', 'fold_groups_param', '_ml_usecase', 'data', 'gpu_n_jobs_param', '_available_plots', 'logging_param', 'pipeline', 'exp_id', 'n_jobs_param', 'y', 'seed', 'USI', 'fold_generator', 'fix_imbalance', 'X_test'}
2023-08-26 12:05:41,684:INFO:Checking environment
2023-08-26 12:05:41,684:INFO:python_version: 3.10.2
2023-08-26 12:05:41,685:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 12:05:41,685:INFO:machine: AMD64
2023-08-26 12:05:41,685:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 12:05:41,690:INFO:Memory: svmem(total=12729561088, available=3895578624, percent=69.4, used=8833982464, free=3895578624)
2023-08-26 12:05:41,691:INFO:Physical Core: 2
2023-08-26 12:05:41,691:INFO:Logical Core: 4
2023-08-26 12:05:41,691:INFO:Checking libraries
2023-08-26 12:05:41,691:INFO:System:
2023-08-26 12:05:41,692:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 12:05:41,692:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 12:05:41,692:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 12:05:41,693:INFO:PyCaret required dependencies:
2023-08-26 12:05:41,693:INFO:                 pip: 23.2.1
2023-08-26 12:05:41,693:INFO:          setuptools: 58.1.0
2023-08-26 12:05:41,693:INFO:             pycaret: 3.0.4
2023-08-26 12:05:41,694:INFO:             IPython: 8.14.0
2023-08-26 12:05:41,694:INFO:          ipywidgets: 8.1.0
2023-08-26 12:05:41,694:INFO:                tqdm: 4.66.1
2023-08-26 12:05:41,694:INFO:               numpy: 1.23.5
2023-08-26 12:05:41,694:INFO:              pandas: 1.5.3
2023-08-26 12:05:41,695:INFO:              jinja2: 3.1.2
2023-08-26 12:05:41,695:INFO:               scipy: 1.11.2
2023-08-26 12:05:41,695:INFO:              joblib: 1.3.2
2023-08-26 12:05:41,695:INFO:             sklearn: 1.2.2
2023-08-26 12:05:41,695:INFO:                pyod: 1.1.0
2023-08-26 12:05:41,696:INFO:            imblearn: 0.11.0
2023-08-26 12:05:41,696:INFO:   category_encoders: 2.6.2
2023-08-26 12:05:41,696:INFO:            lightgbm: 4.0.0
2023-08-26 12:05:41,696:INFO:               numba: 0.57.1
2023-08-26 12:05:41,697:INFO:            requests: 2.31.0
2023-08-26 12:05:41,697:INFO:          matplotlib: 3.7.2
2023-08-26 12:05:41,697:INFO:          scikitplot: 0.3.7
2023-08-26 12:05:41,697:INFO:         yellowbrick: 1.5
2023-08-26 12:05:41,697:INFO:              plotly: 5.16.1
2023-08-26 12:05:41,698:INFO:    plotly-resampler: Not installed
2023-08-26 12:05:41,698:INFO:             kaleido: 0.2.1
2023-08-26 12:05:41,698:INFO:           schemdraw: 0.15
2023-08-26 12:05:41,698:INFO:         statsmodels: 0.14.0
2023-08-26 12:05:41,699:INFO:              sktime: 0.22.0
2023-08-26 12:05:41,699:INFO:               tbats: 1.1.3
2023-08-26 12:05:41,699:INFO:            pmdarima: 2.0.3
2023-08-26 12:05:41,699:INFO:              psutil: 5.9.5
2023-08-26 12:05:41,700:INFO:          markupsafe: 2.1.3
2023-08-26 12:05:41,700:INFO:             pickle5: Not installed
2023-08-26 12:05:41,700:INFO:         cloudpickle: 2.2.1
2023-08-26 12:05:41,700:INFO:         deprecation: 2.1.0
2023-08-26 12:05:41,700:INFO:              xxhash: 3.3.0
2023-08-26 12:05:41,701:INFO:           wurlitzer: Not installed
2023-08-26 12:05:41,701:INFO:PyCaret optional dependencies:
2023-08-26 12:05:41,701:INFO:                shap: Not installed
2023-08-26 12:05:41,702:INFO:           interpret: Not installed
2023-08-26 12:05:41,702:INFO:                umap: Not installed
2023-08-26 12:05:41,702:INFO:    pandas_profiling: Not installed
2023-08-26 12:05:41,702:INFO:  explainerdashboard: Not installed
2023-08-26 12:05:41,702:INFO:             autoviz: Not installed
2023-08-26 12:05:41,703:INFO:           fairlearn: Not installed
2023-08-26 12:05:41,703:INFO:          deepchecks: Not installed
2023-08-26 12:05:41,703:INFO:             xgboost: 1.7.6
2023-08-26 12:05:41,703:INFO:            catboost: Not installed
2023-08-26 12:05:41,704:INFO:              kmodes: Not installed
2023-08-26 12:05:41,704:INFO:             mlxtend: Not installed
2023-08-26 12:05:41,704:INFO:       statsforecast: Not installed
2023-08-26 12:05:41,704:INFO:        tune_sklearn: Not installed
2023-08-26 12:05:41,704:INFO:                 ray: Not installed
2023-08-26 12:05:41,705:INFO:            hyperopt: Not installed
2023-08-26 12:05:41,705:INFO:              optuna: Not installed
2023-08-26 12:05:41,705:INFO:               skopt: Not installed
2023-08-26 12:05:41,705:INFO:              mlflow: Not installed
2023-08-26 12:05:41,706:INFO:              gradio: Not installed
2023-08-26 12:05:41,706:INFO:             fastapi: Not installed
2023-08-26 12:05:41,706:INFO:             uvicorn: Not installed
2023-08-26 12:05:41,707:INFO:              m2cgen: Not installed
2023-08-26 12:05:41,707:INFO:           evidently: Not installed
2023-08-26 12:05:41,707:INFO:               fugue: Not installed
2023-08-26 12:05:41,707:INFO:           streamlit: Not installed
2023-08-26 12:05:41,708:INFO:             prophet: Not installed
2023-08-26 12:05:41,708:INFO:None
2023-08-26 12:05:41,708:INFO:Set up data.
2023-08-26 12:08:57,676:INFO:PyCaret ClassificationExperiment
2023-08-26 12:08:57,676:INFO:Logging name: clf-default-name
2023-08-26 12:08:57,677:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 12:08:57,677:INFO:version 3.0.4
2023-08-26 12:08:57,677:INFO:Initializing setup()
2023-08-26 12:08:57,677:INFO:self.USI: edb5
2023-08-26 12:08:57,678:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'gpu_param', 'idx', 'html_param', 'X', 'memory', 'exp_name_log', 'is_multiclass', 'X_train', 'target_param', 'fold_groups_param', '_ml_usecase', 'data', 'gpu_n_jobs_param', '_available_plots', 'logging_param', 'pipeline', 'exp_id', 'n_jobs_param', 'y', 'seed', 'USI', 'fold_generator', 'fix_imbalance', 'X_test'}
2023-08-26 12:08:57,678:INFO:Checking environment
2023-08-26 12:08:57,679:INFO:python_version: 3.10.2
2023-08-26 12:08:57,679:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 12:08:57,679:INFO:machine: AMD64
2023-08-26 12:08:57,679:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 12:08:57,684:INFO:Memory: svmem(total=12729561088, available=3978850304, percent=68.7, used=8750710784, free=3978850304)
2023-08-26 12:08:57,685:INFO:Physical Core: 2
2023-08-26 12:08:57,685:INFO:Logical Core: 4
2023-08-26 12:08:57,685:INFO:Checking libraries
2023-08-26 12:08:57,686:INFO:System:
2023-08-26 12:08:57,686:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 12:08:57,686:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 12:08:57,686:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 12:08:57,686:INFO:PyCaret required dependencies:
2023-08-26 12:08:57,687:INFO:                 pip: 23.2.1
2023-08-26 12:08:57,687:INFO:          setuptools: 58.1.0
2023-08-26 12:08:57,687:INFO:             pycaret: 3.0.4
2023-08-26 12:08:57,687:INFO:             IPython: 8.14.0
2023-08-26 12:08:57,688:INFO:          ipywidgets: 8.1.0
2023-08-26 12:08:57,688:INFO:                tqdm: 4.66.1
2023-08-26 12:08:57,688:INFO:               numpy: 1.23.5
2023-08-26 12:08:57,688:INFO:              pandas: 1.5.3
2023-08-26 12:08:57,688:INFO:              jinja2: 3.1.2
2023-08-26 12:08:57,689:INFO:               scipy: 1.11.2
2023-08-26 12:08:57,689:INFO:              joblib: 1.3.2
2023-08-26 12:08:57,689:INFO:             sklearn: 1.2.2
2023-08-26 12:08:57,689:INFO:                pyod: 1.1.0
2023-08-26 12:08:57,689:INFO:            imblearn: 0.11.0
2023-08-26 12:08:57,690:INFO:   category_encoders: 2.6.2
2023-08-26 12:08:57,690:INFO:            lightgbm: 4.0.0
2023-08-26 12:08:57,690:INFO:               numba: 0.57.1
2023-08-26 12:08:57,690:INFO:            requests: 2.31.0
2023-08-26 12:08:57,690:INFO:          matplotlib: 3.7.2
2023-08-26 12:08:57,691:INFO:          scikitplot: 0.3.7
2023-08-26 12:08:57,691:INFO:         yellowbrick: 1.5
2023-08-26 12:08:57,691:INFO:              plotly: 5.16.1
2023-08-26 12:08:57,691:INFO:    plotly-resampler: Not installed
2023-08-26 12:08:57,691:INFO:             kaleido: 0.2.1
2023-08-26 12:08:57,692:INFO:           schemdraw: 0.15
2023-08-26 12:08:57,692:INFO:         statsmodels: 0.14.0
2023-08-26 12:08:57,692:INFO:              sktime: 0.22.0
2023-08-26 12:08:57,692:INFO:               tbats: 1.1.3
2023-08-26 12:08:57,692:INFO:            pmdarima: 2.0.3
2023-08-26 12:08:57,693:INFO:              psutil: 5.9.5
2023-08-26 12:08:57,693:INFO:          markupsafe: 2.1.3
2023-08-26 12:08:57,693:INFO:             pickle5: Not installed
2023-08-26 12:08:57,693:INFO:         cloudpickle: 2.2.1
2023-08-26 12:08:57,693:INFO:         deprecation: 2.1.0
2023-08-26 12:08:57,694:INFO:              xxhash: 3.3.0
2023-08-26 12:08:57,694:INFO:           wurlitzer: Not installed
2023-08-26 12:08:57,694:INFO:PyCaret optional dependencies:
2023-08-26 12:08:57,694:INFO:                shap: Not installed
2023-08-26 12:08:57,695:INFO:           interpret: Not installed
2023-08-26 12:08:57,695:INFO:                umap: Not installed
2023-08-26 12:08:57,695:INFO:    pandas_profiling: Not installed
2023-08-26 12:08:57,695:INFO:  explainerdashboard: Not installed
2023-08-26 12:08:57,695:INFO:             autoviz: Not installed
2023-08-26 12:08:57,696:INFO:           fairlearn: Not installed
2023-08-26 12:08:57,696:INFO:          deepchecks: Not installed
2023-08-26 12:08:57,696:INFO:             xgboost: 1.7.6
2023-08-26 12:08:57,696:INFO:            catboost: Not installed
2023-08-26 12:08:57,696:INFO:              kmodes: Not installed
2023-08-26 12:08:57,697:INFO:             mlxtend: Not installed
2023-08-26 12:08:57,697:INFO:       statsforecast: Not installed
2023-08-26 12:08:57,697:INFO:        tune_sklearn: Not installed
2023-08-26 12:08:57,697:INFO:                 ray: Not installed
2023-08-26 12:08:57,698:INFO:            hyperopt: Not installed
2023-08-26 12:08:57,698:INFO:              optuna: Not installed
2023-08-26 12:08:57,698:INFO:               skopt: Not installed
2023-08-26 12:08:57,698:INFO:              mlflow: Not installed
2023-08-26 12:08:57,698:INFO:              gradio: Not installed
2023-08-26 12:08:57,699:INFO:             fastapi: Not installed
2023-08-26 12:08:57,699:INFO:             uvicorn: Not installed
2023-08-26 12:08:57,699:INFO:              m2cgen: Not installed
2023-08-26 12:08:57,700:INFO:           evidently: Not installed
2023-08-26 12:08:57,700:INFO:               fugue: Not installed
2023-08-26 12:08:57,700:INFO:           streamlit: Not installed
2023-08-26 12:08:57,700:INFO:             prophet: Not installed
2023-08-26 12:08:57,701:INFO:None
2023-08-26 12:08:57,701:INFO:Set up data.
2023-08-26 12:08:57,749:INFO:Set up train/test split.
2023-08-26 12:08:57,785:INFO:Set up index.
2023-08-26 12:08:57,787:INFO:Set up folding strategy.
2023-08-26 12:08:57,787:INFO:Assigning column types.
2023-08-26 12:08:57,801:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-26 12:08:58,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:08:58,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:08:58,324:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:08:58,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:08:58,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:08:58,686:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:08:58,786:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:08:58,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:08:58,794:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-26 12:08:59,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:08:59,266:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:08:59,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:08:59,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:08:59,573:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:08:59,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:08:59,585:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-26 12:08:59,990:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:09:00,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:09:00,554:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:09:00,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:09:00,590:INFO:Preparing preprocessing pipeline...
2023-08-26 12:09:00,595:INFO:Set up simple imputation.
2023-08-26 12:09:00,603:INFO:Set up encoding of categorical features.
2023-08-26 12:09:00,904:INFO:Finished creating preprocessing pipeline.
2023-08-26 12:09:00,939:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Gabi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'Year_Birth', 'Income',
                                             'Kidhome', 'Teenhome', 'Recency',
                                             'MntWines', 'MntFruits',
                                             'MntMeatProducts',
                                             'MntFishProducts',
                                             'MntSweetProducts', 'MntGoldProds',
                                             'NumDealsPurchases',
                                             'NumWebPurchases',
                                             'NumCatalogPurc...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Dt_Customer'],
                                    transformer=TargetEncoder(cols=['Dt_Customer'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-08-26 12:09:00,939:INFO:Creating final display dataframe.
2023-08-26 12:09:01,902:INFO:Setup _display_container:                     Description             Value
0                    Session id             10001
1                        Target            target
2                   Target type            Binary
3           Original data shape        (2128, 22)
4        Transformed data shape        (2128, 32)
5   Transformed train set shape        (1489, 32)
6    Transformed test set shape         (639, 32)
7              Numeric features                18
8          Categorical features                 3
9      Rows with missing values              1.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              edb5
2023-08-26 12:09:02,454:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:09:02,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:09:02,844:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:09:02,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:09:02,854:INFO:setup() successfully completed in 5.21s...............
2023-08-26 12:13:50,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:13:50,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:13:50,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:13:50,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:13:58,067:INFO:PyCaret ClassificationExperiment
2023-08-26 12:13:58,068:INFO:Logging name: clf-default-name
2023-08-26 12:13:58,068:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 12:13:58,068:INFO:version 3.0.4
2023-08-26 12:13:58,068:INFO:Initializing setup()
2023-08-26 12:13:58,069:INFO:self.USI: 01ca
2023-08-26 12:13:58,069:INFO:self._variable_keys: {'is_multiclass', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'pipeline', 'X_train', 'log_plots_param', 'X_test', 'X', 'y_train', 'html_param', 'gpu_n_jobs_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', '_ml_usecase', 'exp_name_log', 'n_jobs_param', 'USI', 'exp_id', '_available_plots', 'memory', 'idx', 'fold_generator', 'target_param', 'data', 'seed'}
2023-08-26 12:13:58,069:INFO:Checking environment
2023-08-26 12:13:58,069:INFO:python_version: 3.10.2
2023-08-26 12:13:58,070:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 12:13:58,070:INFO:machine: AMD64
2023-08-26 12:13:58,070:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 12:13:58,074:INFO:Memory: svmem(total=12729561088, available=3928100864, percent=69.1, used=8801460224, free=3928100864)
2023-08-26 12:13:58,075:INFO:Physical Core: 2
2023-08-26 12:13:58,075:INFO:Logical Core: 4
2023-08-26 12:13:58,075:INFO:Checking libraries
2023-08-26 12:13:58,075:INFO:System:
2023-08-26 12:13:58,076:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 12:13:58,076:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 12:13:58,076:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 12:13:58,076:INFO:PyCaret required dependencies:
2023-08-26 12:13:58,136:INFO:                 pip: 23.2.1
2023-08-26 12:13:58,136:INFO:          setuptools: 58.1.0
2023-08-26 12:13:58,136:INFO:             pycaret: 3.0.4
2023-08-26 12:13:58,136:INFO:             IPython: 8.14.0
2023-08-26 12:13:58,137:INFO:          ipywidgets: 8.1.0
2023-08-26 12:13:58,137:INFO:                tqdm: 4.66.1
2023-08-26 12:13:58,137:INFO:               numpy: 1.23.5
2023-08-26 12:13:58,137:INFO:              pandas: 1.5.3
2023-08-26 12:13:58,137:INFO:              jinja2: 3.1.2
2023-08-26 12:13:58,137:INFO:               scipy: 1.11.2
2023-08-26 12:13:58,137:INFO:              joblib: 1.3.2
2023-08-26 12:13:58,138:INFO:             sklearn: 1.2.2
2023-08-26 12:13:58,138:INFO:                pyod: 1.1.0
2023-08-26 12:13:58,138:INFO:            imblearn: 0.11.0
2023-08-26 12:13:58,138:INFO:   category_encoders: 2.6.2
2023-08-26 12:13:58,138:INFO:            lightgbm: 4.0.0
2023-08-26 12:13:58,138:INFO:               numba: 0.57.1
2023-08-26 12:13:58,138:INFO:            requests: 2.31.0
2023-08-26 12:13:58,138:INFO:          matplotlib: 3.7.2
2023-08-26 12:13:58,138:INFO:          scikitplot: 0.3.7
2023-08-26 12:13:58,138:INFO:         yellowbrick: 1.5
2023-08-26 12:13:58,139:INFO:              plotly: 5.16.1
2023-08-26 12:13:58,139:INFO:    plotly-resampler: Not installed
2023-08-26 12:13:58,139:INFO:             kaleido: 0.2.1
2023-08-26 12:13:58,139:INFO:           schemdraw: 0.15
2023-08-26 12:13:58,139:INFO:         statsmodels: 0.14.0
2023-08-26 12:13:58,139:INFO:              sktime: 0.22.0
2023-08-26 12:13:58,139:INFO:               tbats: 1.1.3
2023-08-26 12:13:58,139:INFO:            pmdarima: 2.0.3
2023-08-26 12:13:58,139:INFO:              psutil: 5.9.5
2023-08-26 12:13:58,140:INFO:          markupsafe: 2.1.3
2023-08-26 12:13:58,140:INFO:             pickle5: Not installed
2023-08-26 12:13:58,140:INFO:         cloudpickle: 2.2.1
2023-08-26 12:13:58,140:INFO:         deprecation: 2.1.0
2023-08-26 12:13:58,140:INFO:              xxhash: 3.3.0
2023-08-26 12:13:58,140:INFO:           wurlitzer: Not installed
2023-08-26 12:13:58,140:INFO:PyCaret optional dependencies:
2023-08-26 12:13:58,214:INFO:                shap: Not installed
2023-08-26 12:13:58,214:INFO:           interpret: Not installed
2023-08-26 12:13:58,214:INFO:                umap: Not installed
2023-08-26 12:13:58,214:INFO:    pandas_profiling: Not installed
2023-08-26 12:13:58,215:INFO:  explainerdashboard: Not installed
2023-08-26 12:13:58,215:INFO:             autoviz: Not installed
2023-08-26 12:13:58,215:INFO:           fairlearn: Not installed
2023-08-26 12:13:58,215:INFO:          deepchecks: Not installed
2023-08-26 12:13:58,215:INFO:             xgboost: 1.7.6
2023-08-26 12:13:58,216:INFO:            catboost: Not installed
2023-08-26 12:13:58,216:INFO:              kmodes: Not installed
2023-08-26 12:13:58,216:INFO:             mlxtend: Not installed
2023-08-26 12:13:58,216:INFO:       statsforecast: Not installed
2023-08-26 12:13:58,216:INFO:        tune_sklearn: Not installed
2023-08-26 12:13:58,216:INFO:                 ray: Not installed
2023-08-26 12:13:58,217:INFO:            hyperopt: Not installed
2023-08-26 12:13:58,217:INFO:              optuna: Not installed
2023-08-26 12:13:58,217:INFO:               skopt: Not installed
2023-08-26 12:13:58,217:INFO:              mlflow: Not installed
2023-08-26 12:13:58,217:INFO:              gradio: Not installed
2023-08-26 12:13:58,218:INFO:             fastapi: Not installed
2023-08-26 12:13:58,218:INFO:             uvicorn: Not installed
2023-08-26 12:13:58,218:INFO:              m2cgen: Not installed
2023-08-26 12:13:58,218:INFO:           evidently: Not installed
2023-08-26 12:13:58,218:INFO:               fugue: Not installed
2023-08-26 12:13:58,219:INFO:           streamlit: Not installed
2023-08-26 12:13:58,219:INFO:             prophet: Not installed
2023-08-26 12:13:58,219:INFO:None
2023-08-26 12:13:58,219:INFO:Set up data.
2023-08-26 12:13:58,249:INFO:Set up train/test split.
2023-08-26 12:13:58,266:INFO:Set up index.
2023-08-26 12:13:58,267:INFO:Set up folding strategy.
2023-08-26 12:13:58,267:INFO:Assigning column types.
2023-08-26 12:13:58,283:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-26 12:13:58,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:13:58,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:13:58,530:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:13:58,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:13:58,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:13:58,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:13:58,842:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:13:58,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:13:58,853:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-26 12:13:59,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:13:59,090:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:13:59,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:13:59,251:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:13:59,528:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:13:59,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:13:59,536:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-26 12:13:59,801:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:13:59,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:14:00,083:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:14:00,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:14:00,097:INFO:Preparing preprocessing pipeline...
2023-08-26 12:14:00,098:INFO:Set up simple imputation.
2023-08-26 12:14:00,103:INFO:Set up encoding of categorical features.
2023-08-26 12:14:00,339:INFO:Finished creating preprocessing pipeline.
2023-08-26 12:14:00,356:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Gabi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'Year_Birth', 'Income',
                                             'Kidhome', 'Teenhome', 'Recency',
                                             'MntWines', 'MntFruits',
                                             'MntMeatProducts',
                                             'MntFishProducts',
                                             'MntSweetProducts', 'MntGoldProds',
                                             'NumDealsPurchases',
                                             'NumWebPurchases',
                                             'NumCatalogPurc...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Dt_Customer'],
                                    transformer=TargetEncoder(cols=['Dt_Customer'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-08-26 12:14:00,356:INFO:Creating final display dataframe.
2023-08-26 12:14:01,035:INFO:Setup _display_container:                     Description             Value
0                    Session id             10001
1                        Target          Response
2                   Target type            Binary
3           Original data shape        (2128, 22)
4        Transformed data shape        (2128, 32)
5   Transformed train set shape        (1489, 32)
6    Transformed test set shape         (639, 32)
7              Numeric features                18
8          Categorical features                 3
9      Rows with missing values              1.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              01ca
2023-08-26 12:14:01,331:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:14:01,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:14:01,570:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:14:01,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:14:01,580:INFO:setup() successfully completed in 3.53s...............
2023-08-26 12:14:08,188:INFO:Initializing compare_models()
2023-08-26 12:14:08,188:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-26 12:14:08,189:INFO:Checking exceptions
2023-08-26 12:14:08,200:INFO:Preparing display monitor
2023-08-26 12:14:08,271:INFO:Initializing Logistic Regression
2023-08-26 12:14:08,271:INFO:Total runtime is 0.0 minutes
2023-08-26 12:14:08,281:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:08,281:INFO:Initializing create_model()
2023-08-26 12:14:08,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:08,282:INFO:Checking exceptions
2023-08-26 12:14:08,283:INFO:Importing libraries
2023-08-26 12:14:08,285:INFO:Copying training dataset
2023-08-26 12:14:08,304:INFO:Defining folds
2023-08-26 12:14:08,305:INFO:Declaring metric variables
2023-08-26 12:14:08,315:INFO:Importing untrained model
2023-08-26 12:14:08,324:INFO:Logistic Regression Imported successfully
2023-08-26 12:14:08,344:INFO:Starting cross validation
2023-08-26 12:14:08,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:22,008:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:14:24,394:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:14:24,827:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:14:24,919:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:14:26,055:INFO:Calculating mean and std
2023-08-26 12:14:26,064:INFO:Creating metrics dataframe
2023-08-26 12:14:26,150:INFO:Uploading results into container
2023-08-26 12:14:26,151:INFO:Uploading model into container now
2023-08-26 12:14:26,153:INFO:_master_model_container: 1
2023-08-26 12:14:26,155:INFO:_display_container: 2
2023-08-26 12:14:26,157:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:14:26,158:INFO:create_model() successfully completed......................................
2023-08-26 12:14:26,338:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:26,339:INFO:Creating metrics dataframe
2023-08-26 12:14:26,388:INFO:Initializing K Neighbors Classifier
2023-08-26 12:14:26,389:INFO:Total runtime is 0.30193866888682047 minutes
2023-08-26 12:14:26,400:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:26,401:INFO:Initializing create_model()
2023-08-26 12:14:26,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:26,401:INFO:Checking exceptions
2023-08-26 12:14:26,402:INFO:Importing libraries
2023-08-26 12:14:26,402:INFO:Copying training dataset
2023-08-26 12:14:26,424:INFO:Defining folds
2023-08-26 12:14:26,424:INFO:Declaring metric variables
2023-08-26 12:14:26,435:INFO:Importing untrained model
2023-08-26 12:14:26,449:INFO:K Neighbors Classifier Imported successfully
2023-08-26 12:14:26,488:INFO:Starting cross validation
2023-08-26 12:14:26,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:31,763:INFO:Calculating mean and std
2023-08-26 12:14:31,767:INFO:Creating metrics dataframe
2023-08-26 12:14:31,859:INFO:Uploading results into container
2023-08-26 12:14:31,860:INFO:Uploading model into container now
2023-08-26 12:14:31,861:INFO:_master_model_container: 2
2023-08-26 12:14:31,861:INFO:_display_container: 2
2023-08-26 12:14:31,861:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-26 12:14:31,862:INFO:create_model() successfully completed......................................
2023-08-26 12:14:31,963:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:31,964:INFO:Creating metrics dataframe
2023-08-26 12:14:31,988:INFO:Initializing Naive Bayes
2023-08-26 12:14:31,988:INFO:Total runtime is 0.3952810009320577 minutes
2023-08-26 12:14:31,997:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:31,998:INFO:Initializing create_model()
2023-08-26 12:14:31,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:31,998:INFO:Checking exceptions
2023-08-26 12:14:31,999:INFO:Importing libraries
2023-08-26 12:14:31,999:INFO:Copying training dataset
2023-08-26 12:14:32,014:INFO:Defining folds
2023-08-26 12:14:32,014:INFO:Declaring metric variables
2023-08-26 12:14:32,035:INFO:Importing untrained model
2023-08-26 12:14:32,058:INFO:Naive Bayes Imported successfully
2023-08-26 12:14:32,086:INFO:Starting cross validation
2023-08-26 12:14:32,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:36,785:INFO:Calculating mean and std
2023-08-26 12:14:36,789:INFO:Creating metrics dataframe
2023-08-26 12:14:36,889:INFO:Uploading results into container
2023-08-26 12:14:36,891:INFO:Uploading model into container now
2023-08-26 12:14:36,894:INFO:_master_model_container: 3
2023-08-26 12:14:36,895:INFO:_display_container: 2
2023-08-26 12:14:36,895:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-26 12:14:36,896:INFO:create_model() successfully completed......................................
2023-08-26 12:14:36,998:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:36,998:INFO:Creating metrics dataframe
2023-08-26 12:14:37,019:INFO:Initializing Decision Tree Classifier
2023-08-26 12:14:37,019:INFO:Total runtime is 0.47912915150324503 minutes
2023-08-26 12:14:37,030:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:37,031:INFO:Initializing create_model()
2023-08-26 12:14:37,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:37,031:INFO:Checking exceptions
2023-08-26 12:14:37,031:INFO:Importing libraries
2023-08-26 12:14:37,031:INFO:Copying training dataset
2023-08-26 12:14:37,050:INFO:Defining folds
2023-08-26 12:14:37,051:INFO:Declaring metric variables
2023-08-26 12:14:37,067:INFO:Importing untrained model
2023-08-26 12:14:37,084:INFO:Decision Tree Classifier Imported successfully
2023-08-26 12:14:37,110:INFO:Starting cross validation
2023-08-26 12:14:37,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:41,239:INFO:Calculating mean and std
2023-08-26 12:14:41,244:INFO:Creating metrics dataframe
2023-08-26 12:14:41,372:INFO:Uploading results into container
2023-08-26 12:14:41,373:INFO:Uploading model into container now
2023-08-26 12:14:41,374:INFO:_master_model_container: 4
2023-08-26 12:14:41,374:INFO:_display_container: 2
2023-08-26 12:14:41,376:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=10001, splitter='best')
2023-08-26 12:14:41,376:INFO:create_model() successfully completed......................................
2023-08-26 12:14:41,496:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:41,496:INFO:Creating metrics dataframe
2023-08-26 12:14:41,524:INFO:Initializing SVM - Linear Kernel
2023-08-26 12:14:41,524:INFO:Total runtime is 0.5542160828908285 minutes
2023-08-26 12:14:41,532:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:41,533:INFO:Initializing create_model()
2023-08-26 12:14:41,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:41,533:INFO:Checking exceptions
2023-08-26 12:14:41,534:INFO:Importing libraries
2023-08-26 12:14:41,534:INFO:Copying training dataset
2023-08-26 12:14:41,551:INFO:Defining folds
2023-08-26 12:14:41,551:INFO:Declaring metric variables
2023-08-26 12:14:41,561:INFO:Importing untrained model
2023-08-26 12:14:41,578:INFO:SVM - Linear Kernel Imported successfully
2023-08-26 12:14:41,603:INFO:Starting cross validation
2023-08-26 12:14:41,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:43,006:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:43,006:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:43,007:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:43,043:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:43,044:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:43,061:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:43,388:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:43,419:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:44,481:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:44,513:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:44,644:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:44,656:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:44,852:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:44,881:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:45,824:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:45,832:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:45,843:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:14:45,858:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:14:45,969:INFO:Calculating mean and std
2023-08-26 12:14:45,972:INFO:Creating metrics dataframe
2023-08-26 12:14:46,108:INFO:Uploading results into container
2023-08-26 12:14:46,110:INFO:Uploading model into container now
2023-08-26 12:14:46,112:INFO:_master_model_container: 5
2023-08-26 12:14:46,112:INFO:_display_container: 2
2023-08-26 12:14:46,114:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=10001, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-26 12:14:46,114:INFO:create_model() successfully completed......................................
2023-08-26 12:14:46,228:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:46,229:INFO:Creating metrics dataframe
2023-08-26 12:14:46,255:INFO:Initializing Ridge Classifier
2023-08-26 12:14:46,255:INFO:Total runtime is 0.6330674091974895 minutes
2023-08-26 12:14:46,285:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:46,286:INFO:Initializing create_model()
2023-08-26 12:14:46,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:46,287:INFO:Checking exceptions
2023-08-26 12:14:46,287:INFO:Importing libraries
2023-08-26 12:14:46,287:INFO:Copying training dataset
2023-08-26 12:14:46,312:INFO:Defining folds
2023-08-26 12:14:46,313:INFO:Declaring metric variables
2023-08-26 12:14:46,325:INFO:Importing untrained model
2023-08-26 12:14:46,387:INFO:Ridge Classifier Imported successfully
2023-08-26 12:14:46,408:INFO:Starting cross validation
2023-08-26 12:14:46,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:47,799:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:47,815:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:47,878:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:47,894:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:49,277:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:49,288:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:49,296:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:49,517:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:50,461:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:50,581:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:14:50,632:INFO:Calculating mean and std
2023-08-26 12:14:50,638:INFO:Creating metrics dataframe
2023-08-26 12:14:50,803:INFO:Uploading results into container
2023-08-26 12:14:50,807:INFO:Uploading model into container now
2023-08-26 12:14:50,809:INFO:_master_model_container: 6
2023-08-26 12:14:50,809:INFO:_display_container: 2
2023-08-26 12:14:50,810:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=10001,
                solver='auto', tol=0.0001)
2023-08-26 12:14:50,811:INFO:create_model() successfully completed......................................
2023-08-26 12:14:50,926:INFO:SubProcess create_model() end ==================================
2023-08-26 12:14:50,926:INFO:Creating metrics dataframe
2023-08-26 12:14:50,951:INFO:Initializing Random Forest Classifier
2023-08-26 12:14:50,951:INFO:Total runtime is 0.7113357067108155 minutes
2023-08-26 12:14:50,962:INFO:SubProcess create_model() called ==================================
2023-08-26 12:14:50,963:INFO:Initializing create_model()
2023-08-26 12:14:50,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:14:50,963:INFO:Checking exceptions
2023-08-26 12:14:50,963:INFO:Importing libraries
2023-08-26 12:14:50,964:INFO:Copying training dataset
2023-08-26 12:14:50,981:INFO:Defining folds
2023-08-26 12:14:50,983:INFO:Declaring metric variables
2023-08-26 12:14:50,996:INFO:Importing untrained model
2023-08-26 12:14:51,013:INFO:Random Forest Classifier Imported successfully
2023-08-26 12:14:51,041:INFO:Starting cross validation
2023-08-26 12:14:51,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:14:53,709:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:53,722:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:53,754:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:54,137:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:55,591:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:14:55,729:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:14:55,738:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:14:55,970:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:14:59,374:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:59,428:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:14:59,878:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:00,704:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:01,006:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:01,120:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:01,438:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:02,312:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:05,694:INFO:Calculating mean and std
2023-08-26 12:15:05,701:INFO:Creating metrics dataframe
2023-08-26 12:15:05,887:INFO:Uploading results into container
2023-08-26 12:15:05,889:INFO:Uploading model into container now
2023-08-26 12:15:05,890:INFO:_master_model_container: 7
2023-08-26 12:15:05,892:INFO:_display_container: 2
2023-08-26 12:15:05,893:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=10001, verbose=0, warm_start=False)
2023-08-26 12:15:05,894:INFO:create_model() successfully completed......................................
2023-08-26 12:15:06,013:INFO:SubProcess create_model() end ==================================
2023-08-26 12:15:06,013:INFO:Creating metrics dataframe
2023-08-26 12:15:06,044:INFO:Initializing Quadratic Discriminant Analysis
2023-08-26 12:15:06,044:INFO:Total runtime is 0.962880273660024 minutes
2023-08-26 12:15:06,055:INFO:SubProcess create_model() called ==================================
2023-08-26 12:15:06,056:INFO:Initializing create_model()
2023-08-26 12:15:06,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:15:06,056:INFO:Checking exceptions
2023-08-26 12:15:06,057:INFO:Importing libraries
2023-08-26 12:15:06,057:INFO:Copying training dataset
2023-08-26 12:15:06,072:INFO:Defining folds
2023-08-26 12:15:06,073:INFO:Declaring metric variables
2023-08-26 12:15:06,089:INFO:Importing untrained model
2023-08-26 12:15:06,110:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-26 12:15:06,141:INFO:Starting cross validation
2023-08-26 12:15:06,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:15:06,693:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:06,720:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:07,574:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:15:08,428:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:08,429:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:08,532:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:08,748:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:09,247:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:15:10,069:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:10,112:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:15:10,642:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:15:10,650:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:15:10,846:INFO:Calculating mean and std
2023-08-26 12:15:10,853:INFO:Creating metrics dataframe
2023-08-26 12:15:11,105:INFO:Uploading results into container
2023-08-26 12:15:11,107:INFO:Uploading model into container now
2023-08-26 12:15:11,108:INFO:_master_model_container: 8
2023-08-26 12:15:11,109:INFO:_display_container: 2
2023-08-26 12:15:11,110:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-26 12:15:11,110:INFO:create_model() successfully completed......................................
2023-08-26 12:15:11,293:INFO:SubProcess create_model() end ==================================
2023-08-26 12:15:11,294:INFO:Creating metrics dataframe
2023-08-26 12:15:11,337:INFO:Initializing Ada Boost Classifier
2023-08-26 12:15:11,337:INFO:Total runtime is 1.0510924537976583 minutes
2023-08-26 12:15:11,346:INFO:SubProcess create_model() called ==================================
2023-08-26 12:15:11,346:INFO:Initializing create_model()
2023-08-26 12:15:11,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:15:11,347:INFO:Checking exceptions
2023-08-26 12:15:11,347:INFO:Importing libraries
2023-08-26 12:15:11,347:INFO:Copying training dataset
2023-08-26 12:15:11,359:INFO:Defining folds
2023-08-26 12:15:11,360:INFO:Declaring metric variables
2023-08-26 12:15:11,372:INFO:Importing untrained model
2023-08-26 12:15:11,385:INFO:Ada Boost Classifier Imported successfully
2023-08-26 12:15:11,411:INFO:Starting cross validation
2023-08-26 12:15:11,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:15:21,568:INFO:Calculating mean and std
2023-08-26 12:15:21,572:INFO:Creating metrics dataframe
2023-08-26 12:15:21,844:INFO:Uploading results into container
2023-08-26 12:15:21,846:INFO:Uploading model into container now
2023-08-26 12:15:21,849:INFO:_master_model_container: 9
2023-08-26 12:15:21,849:INFO:_display_container: 2
2023-08-26 12:15:21,850:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=10001)
2023-08-26 12:15:21,850:INFO:create_model() successfully completed......................................
2023-08-26 12:15:21,965:INFO:SubProcess create_model() end ==================================
2023-08-26 12:15:21,965:INFO:Creating metrics dataframe
2023-08-26 12:15:21,997:INFO:Initializing Gradient Boosting Classifier
2023-08-26 12:15:21,998:INFO:Total runtime is 1.2287826458613078 minutes
2023-08-26 12:15:22,010:INFO:SubProcess create_model() called ==================================
2023-08-26 12:15:22,011:INFO:Initializing create_model()
2023-08-26 12:15:22,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:15:22,012:INFO:Checking exceptions
2023-08-26 12:15:22,012:INFO:Importing libraries
2023-08-26 12:15:22,012:INFO:Copying training dataset
2023-08-26 12:15:22,044:INFO:Defining folds
2023-08-26 12:15:22,045:INFO:Declaring metric variables
2023-08-26 12:15:22,058:INFO:Importing untrained model
2023-08-26 12:15:22,085:INFO:Gradient Boosting Classifier Imported successfully
2023-08-26 12:15:22,112:INFO:Starting cross validation
2023-08-26 12:15:22,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:15:30,601:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:30,910:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:31,261:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:31,603:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:33,200:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:33,306:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:34,037:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:34,250:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:37,871:INFO:Calculating mean and std
2023-08-26 12:15:37,875:INFO:Creating metrics dataframe
2023-08-26 12:15:38,160:INFO:Uploading results into container
2023-08-26 12:15:38,162:INFO:Uploading model into container now
2023-08-26 12:15:38,165:INFO:_master_model_container: 10
2023-08-26 12:15:38,165:INFO:_display_container: 2
2023-08-26 12:15:38,167:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=10001, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-26 12:15:38,167:INFO:create_model() successfully completed......................................
2023-08-26 12:15:38,272:INFO:SubProcess create_model() end ==================================
2023-08-26 12:15:38,273:INFO:Creating metrics dataframe
2023-08-26 12:15:38,303:INFO:Initializing Linear Discriminant Analysis
2023-08-26 12:15:38,303:INFO:Total runtime is 1.5005314071973166 minutes
2023-08-26 12:15:38,313:INFO:SubProcess create_model() called ==================================
2023-08-26 12:15:38,314:INFO:Initializing create_model()
2023-08-26 12:15:38,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:15:38,314:INFO:Checking exceptions
2023-08-26 12:15:38,315:INFO:Importing libraries
2023-08-26 12:15:38,315:INFO:Copying training dataset
2023-08-26 12:15:38,332:INFO:Defining folds
2023-08-26 12:15:38,332:INFO:Declaring metric variables
2023-08-26 12:15:38,343:INFO:Importing untrained model
2023-08-26 12:15:38,354:INFO:Linear Discriminant Analysis Imported successfully
2023-08-26 12:15:38,394:INFO:Starting cross validation
2023-08-26 12:15:38,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:15:44,983:INFO:Calculating mean and std
2023-08-26 12:15:44,989:INFO:Creating metrics dataframe
2023-08-26 12:15:45,334:INFO:Uploading results into container
2023-08-26 12:15:45,336:INFO:Uploading model into container now
2023-08-26 12:15:45,339:INFO:_master_model_container: 11
2023-08-26 12:15:45,340:INFO:_display_container: 2
2023-08-26 12:15:45,341:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-26 12:15:45,341:INFO:create_model() successfully completed......................................
2023-08-26 12:15:45,451:INFO:SubProcess create_model() end ==================================
2023-08-26 12:15:45,452:INFO:Creating metrics dataframe
2023-08-26 12:15:45,494:INFO:Initializing Extra Trees Classifier
2023-08-26 12:15:45,494:INFO:Total runtime is 1.6203740557034811 minutes
2023-08-26 12:15:45,505:INFO:SubProcess create_model() called ==================================
2023-08-26 12:15:45,506:INFO:Initializing create_model()
2023-08-26 12:15:45,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:15:45,507:INFO:Checking exceptions
2023-08-26 12:15:45,508:INFO:Importing libraries
2023-08-26 12:15:45,508:INFO:Copying training dataset
2023-08-26 12:15:45,540:INFO:Defining folds
2023-08-26 12:15:45,543:INFO:Declaring metric variables
2023-08-26 12:15:45,561:INFO:Importing untrained model
2023-08-26 12:15:45,579:INFO:Extra Trees Classifier Imported successfully
2023-08-26 12:15:45,609:INFO:Starting cross validation
2023-08-26 12:15:45,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:15:49,393:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:49,408:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:15:57,903:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:57,955:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:15:59,936:INFO:Calculating mean and std
2023-08-26 12:15:59,940:INFO:Creating metrics dataframe
2023-08-26 12:16:00,301:INFO:Uploading results into container
2023-08-26 12:16:00,302:INFO:Uploading model into container now
2023-08-26 12:16:00,305:INFO:_master_model_container: 12
2023-08-26 12:16:00,306:INFO:_display_container: 2
2023-08-26 12:16:00,308:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=10001, verbose=0, warm_start=False)
2023-08-26 12:16:00,309:INFO:create_model() successfully completed......................................
2023-08-26 12:16:00,435:INFO:SubProcess create_model() end ==================================
2023-08-26 12:16:00,435:INFO:Creating metrics dataframe
2023-08-26 12:16:00,468:INFO:Initializing Extreme Gradient Boosting
2023-08-26 12:16:00,469:INFO:Total runtime is 1.8699703613917034 minutes
2023-08-26 12:16:00,480:INFO:SubProcess create_model() called ==================================
2023-08-26 12:16:00,481:INFO:Initializing create_model()
2023-08-26 12:16:00,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:16:00,482:INFO:Checking exceptions
2023-08-26 12:16:00,482:INFO:Importing libraries
2023-08-26 12:16:00,482:INFO:Copying training dataset
2023-08-26 12:16:00,504:INFO:Defining folds
2023-08-26 12:16:00,505:INFO:Declaring metric variables
2023-08-26 12:16:00,515:INFO:Importing untrained model
2023-08-26 12:16:00,535:INFO:Extreme Gradient Boosting Imported successfully
2023-08-26 12:16:00,588:INFO:Starting cross validation
2023-08-26 12:16:00,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:16:03,926:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:16:03,968:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:16:04,163:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:16:12,064:INFO:Calculating mean and std
2023-08-26 12:16:12,069:INFO:Creating metrics dataframe
2023-08-26 12:16:12,416:INFO:Uploading results into container
2023-08-26 12:16:12,417:INFO:Uploading model into container now
2023-08-26 12:16:12,419:INFO:_master_model_container: 13
2023-08-26 12:16:12,419:INFO:_display_container: 2
2023-08-26 12:16:12,423:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-26 12:16:12,424:INFO:create_model() successfully completed......................................
2023-08-26 12:16:12,533:INFO:SubProcess create_model() end ==================================
2023-08-26 12:16:12,534:INFO:Creating metrics dataframe
2023-08-26 12:16:12,577:INFO:Initializing Light Gradient Boosting Machine
2023-08-26 12:16:12,577:INFO:Total runtime is 2.0717709104220075 minutes
2023-08-26 12:16:12,588:INFO:SubProcess create_model() called ==================================
2023-08-26 12:16:12,589:INFO:Initializing create_model()
2023-08-26 12:16:12,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:16:12,590:INFO:Checking exceptions
2023-08-26 12:16:12,590:INFO:Importing libraries
2023-08-26 12:16:12,590:INFO:Copying training dataset
2023-08-26 12:16:12,607:INFO:Defining folds
2023-08-26 12:16:12,608:INFO:Declaring metric variables
2023-08-26 12:16:12,620:INFO:Importing untrained model
2023-08-26 12:16:12,633:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-26 12:16:12,659:INFO:Starting cross validation
2023-08-26 12:16:12,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:16:19,991:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:16:22,194:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:16:26,145:INFO:Calculating mean and std
2023-08-26 12:16:26,156:INFO:Creating metrics dataframe
2023-08-26 12:16:27,020:INFO:Uploading results into container
2023-08-26 12:16:27,025:INFO:Uploading model into container now
2023-08-26 12:16:27,027:INFO:_master_model_container: 14
2023-08-26 12:16:27,028:INFO:_display_container: 2
2023-08-26 12:16:27,032:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=10001, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-26 12:16:27,033:INFO:create_model() successfully completed......................................
2023-08-26 12:16:27,308:INFO:SubProcess create_model() end ==================================
2023-08-26 12:16:27,309:INFO:Creating metrics dataframe
2023-08-26 12:16:27,402:INFO:Initializing Dummy Classifier
2023-08-26 12:16:27,403:INFO:Total runtime is 2.31886823574702 minutes
2023-08-26 12:16:27,421:INFO:SubProcess create_model() called ==================================
2023-08-26 12:16:27,422:INFO:Initializing create_model()
2023-08-26 12:16:27,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021C4B8124D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:16:27,423:INFO:Checking exceptions
2023-08-26 12:16:27,423:INFO:Importing libraries
2023-08-26 12:16:27,423:INFO:Copying training dataset
2023-08-26 12:16:27,449:INFO:Defining folds
2023-08-26 12:16:27,449:INFO:Declaring metric variables
2023-08-26 12:16:27,467:INFO:Importing untrained model
2023-08-26 12:16:27,480:INFO:Dummy Classifier Imported successfully
2023-08-26 12:16:27,515:INFO:Starting cross validation
2023-08-26 12:16:27,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:16:28,949:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:28,974:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:29,080:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:29,207:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:31,063:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:31,195:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:31,220:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:31,504:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:33,031:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:33,039:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:16:34,171:INFO:Calculating mean and std
2023-08-26 12:16:34,175:INFO:Creating metrics dataframe
2023-08-26 12:16:34,667:INFO:Uploading results into container
2023-08-26 12:16:34,668:INFO:Uploading model into container now
2023-08-26 12:16:34,670:INFO:_master_model_container: 15
2023-08-26 12:16:34,671:INFO:_display_container: 2
2023-08-26 12:16:34,672:INFO:DummyClassifier(constant=None, random_state=10001, strategy='prior')
2023-08-26 12:16:34,672:INFO:create_model() successfully completed......................................
2023-08-26 12:16:34,786:INFO:SubProcess create_model() end ==================================
2023-08-26 12:16:34,786:INFO:Creating metrics dataframe
2023-08-26 12:16:34,853:INFO:Initializing create_model()
2023-08-26 12:16:34,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:16:34,854:INFO:Checking exceptions
2023-08-26 12:16:34,859:INFO:Importing libraries
2023-08-26 12:16:34,861:INFO:Copying training dataset
2023-08-26 12:16:34,883:INFO:Defining folds
2023-08-26 12:16:34,883:INFO:Declaring metric variables
2023-08-26 12:16:34,883:INFO:Importing untrained model
2023-08-26 12:16:34,884:INFO:Declaring custom model
2023-08-26 12:16:34,886:INFO:Logistic Regression Imported successfully
2023-08-26 12:16:34,891:INFO:Cross validation set to False
2023-08-26 12:16:34,891:INFO:Fitting Model
2023-08-26 12:16:36,383:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:16:36,383:INFO:create_model() successfully completed......................................
2023-08-26 12:16:36,582:INFO:_master_model_container: 15
2023-08-26 12:16:36,582:INFO:_display_container: 2
2023-08-26 12:16:36,584:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:16:36,584:INFO:compare_models() successfully completed......................................
2023-08-26 12:17:02,050:INFO:gpu_param set to False
2023-08-26 12:17:02,366:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:17:02,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:17:02,762:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:17:02,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:17:15,117:INFO:Initializing create_model()
2023-08-26 12:17:15,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:17:15,118:INFO:Checking exceptions
2023-08-26 12:17:15,154:INFO:Importing libraries
2023-08-26 12:17:15,154:INFO:Copying training dataset
2023-08-26 12:17:15,169:INFO:Defining folds
2023-08-26 12:17:15,169:INFO:Declaring metric variables
2023-08-26 12:17:15,175:INFO:Importing untrained model
2023-08-26 12:17:15,181:INFO:Decision Tree Classifier Imported successfully
2023-08-26 12:17:15,196:INFO:Starting cross validation
2023-08-26 12:17:15,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:17:21,863:INFO:Calculating mean and std
2023-08-26 12:17:21,866:INFO:Creating metrics dataframe
2023-08-26 12:17:21,886:INFO:Finalizing model
2023-08-26 12:17:22,572:INFO:Uploading results into container
2023-08-26 12:17:22,574:INFO:Uploading model into container now
2023-08-26 12:17:22,624:INFO:_master_model_container: 16
2023-08-26 12:17:22,624:INFO:_display_container: 3
2023-08-26 12:17:22,626:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=10001, splitter='best')
2023-08-26 12:17:22,627:INFO:create_model() successfully completed......................................
2023-08-26 12:18:36,065:INFO:Initializing create_model()
2023-08-26 12:18:36,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:18:36,066:INFO:Checking exceptions
2023-08-26 12:18:36,103:INFO:Importing libraries
2023-08-26 12:18:36,103:INFO:Copying training dataset
2023-08-26 12:18:36,123:INFO:Defining folds
2023-08-26 12:18:36,123:INFO:Declaring metric variables
2023-08-26 12:18:36,132:INFO:Importing untrained model
2023-08-26 12:18:36,143:INFO:Logistic Regression Imported successfully
2023-08-26 12:18:36,160:INFO:Starting cross validation
2023-08-26 12:18:36,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:18:43,707:INFO:Calculating mean and std
2023-08-26 12:18:43,710:INFO:Creating metrics dataframe
2023-08-26 12:18:43,724:INFO:Finalizing model
2023-08-26 12:18:44,475:INFO:Uploading results into container
2023-08-26 12:18:44,477:INFO:Uploading model into container now
2023-08-26 12:18:44,518:INFO:_master_model_container: 17
2023-08-26 12:18:44,518:INFO:_display_container: 4
2023-08-26 12:18:44,519:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:18:44,520:INFO:create_model() successfully completed......................................
2023-08-26 12:20:50,855:INFO:Initializing create_model()
2023-08-26 12:20:50,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:20:50,855:INFO:Checking exceptions
2023-08-26 12:20:50,891:INFO:Importing libraries
2023-08-26 12:20:50,891:INFO:Copying training dataset
2023-08-26 12:20:50,906:INFO:Defining folds
2023-08-26 12:20:50,906:INFO:Declaring metric variables
2023-08-26 12:20:50,915:INFO:Importing untrained model
2023-08-26 12:20:50,926:INFO:Naive Bayes Imported successfully
2023-08-26 12:20:50,947:INFO:Starting cross validation
2023-08-26 12:20:50,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:20:56,526:INFO:Calculating mean and std
2023-08-26 12:20:56,528:INFO:Creating metrics dataframe
2023-08-26 12:20:56,542:INFO:Finalizing model
2023-08-26 12:20:57,098:INFO:Uploading results into container
2023-08-26 12:20:57,100:INFO:Uploading model into container now
2023-08-26 12:20:57,130:INFO:_master_model_container: 18
2023-08-26 12:20:57,131:INFO:_display_container: 5
2023-08-26 12:20:57,131:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-26 12:20:57,131:INFO:create_model() successfully completed......................................
2023-08-26 12:21:50,565:INFO:Initializing create_model()
2023-08-26 12:21:50,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:21:50,565:INFO:Checking exceptions
2023-08-26 12:21:50,603:INFO:Importing libraries
2023-08-26 12:21:50,604:INFO:Copying training dataset
2023-08-26 12:21:50,621:INFO:Defining folds
2023-08-26 12:21:50,621:INFO:Declaring metric variables
2023-08-26 12:21:50,628:INFO:Importing untrained model
2023-08-26 12:21:50,636:INFO:Logistic Regression Imported successfully
2023-08-26 12:21:50,651:INFO:Starting cross validation
2023-08-26 12:21:50,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:21:56,158:INFO:Calculating mean and std
2023-08-26 12:21:56,160:INFO:Creating metrics dataframe
2023-08-26 12:21:56,179:INFO:Finalizing model
2023-08-26 12:21:57,089:INFO:Uploading results into container
2023-08-26 12:21:57,091:INFO:Uploading model into container now
2023-08-26 12:21:57,129:INFO:_master_model_container: 19
2023-08-26 12:21:57,129:INFO:_display_container: 6
2023-08-26 12:21:57,131:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:21:57,131:INFO:create_model() successfully completed......................................
2023-08-26 12:25:47,753:INFO:Initializing create_model()
2023-08-26 12:25:47,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:25:47,753:INFO:Checking exceptions
2023-08-26 12:25:47,787:INFO:Importing libraries
2023-08-26 12:25:47,787:INFO:Copying training dataset
2023-08-26 12:25:47,807:INFO:Defining folds
2023-08-26 12:25:47,807:INFO:Declaring metric variables
2023-08-26 12:25:47,816:INFO:Importing untrained model
2023-08-26 12:25:47,835:INFO:Gradient Boosting Classifier Imported successfully
2023-08-26 12:25:47,849:INFO:Starting cross validation
2023-08-26 12:25:47,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:25:49,876:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:49,878:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:50,399:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:52,746:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:52,870:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:52,997:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:25:55,743:INFO:Calculating mean and std
2023-08-26 12:25:55,748:INFO:Creating metrics dataframe
2023-08-26 12:25:55,769:INFO:Finalizing model
2023-08-26 12:25:57,539:INFO:Uploading results into container
2023-08-26 12:25:57,542:INFO:Uploading model into container now
2023-08-26 12:25:57,583:INFO:_master_model_container: 20
2023-08-26 12:25:57,588:INFO:_display_container: 7
2023-08-26 12:25:57,591:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=10001, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-26 12:25:57,592:INFO:create_model() successfully completed......................................
2023-08-26 12:31:34,684:INFO:Initializing tune_model()
2023-08-26 12:31:34,685:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021C4B8106D0>)
2023-08-26 12:31:34,685:INFO:Checking exceptions
2023-08-26 12:31:34,724:INFO:Copying training dataset
2023-08-26 12:31:34,733:INFO:Checking base model
2023-08-26 12:31:34,733:INFO:Base model : Logistic Regression
2023-08-26 12:31:34,740:INFO:Declaring metric variables
2023-08-26 12:31:34,746:INFO:Defining Hyperparameters
2023-08-26 12:31:34,977:INFO:Tuning with n_jobs=-1
2023-08-26 12:31:34,977:INFO:Initializing RandomizedSearchCV
2023-08-26 12:31:47,736:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:47,799:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:47,993:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:48,159:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:52,034:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:52,587:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:55,157:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:56,568:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:56,676:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:57,492:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:31:59,259:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:32:00,842:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:32:02,049:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:02,066:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:02,625:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:32:03,485:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:07,391:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:07,426:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:32:08,411:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:12,723:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:13,164:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:13,526:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:15,308:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:18,131:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:21,627:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:24,431:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:26,761:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:29,171:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:32:30,761:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:31,045:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:31,813:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:33,971:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:35,789:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:36,754:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:38,608:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:32:39,370:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:41,092:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:42,323:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:42,818:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:32:42,898:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:32:47,833:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:49,985:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:51,759:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:32:53,388:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:32:56,708:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:33:23,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:33:23,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:33:23,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:33:23,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-26 12:33:25,735:INFO:PyCaret ClassificationExperiment
2023-08-26 12:33:25,735:INFO:Logging name: clf-default-name
2023-08-26 12:33:25,736:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-26 12:33:25,736:INFO:version 3.0.4
2023-08-26 12:33:25,736:INFO:Initializing setup()
2023-08-26 12:33:25,736:INFO:self.USI: 004b
2023-08-26 12:33:25,736:INFO:self._variable_keys: {'data', 'USI', 'X_test', 'idx', 'pipeline', 'y_train', 'gpu_n_jobs_param', 'exp_name_log', 'exp_id', '_available_plots', 'fold_shuffle_param', 'X_train', 'target_param', 'html_param', 'memory', 'seed', 'fold_groups_param', 'X', 'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'logging_param', 'y', 'fold_generator', 'is_multiclass', 'log_plots_param', 'gpu_param', 'y_test'}
2023-08-26 12:33:25,736:INFO:Checking environment
2023-08-26 12:33:25,737:INFO:python_version: 3.10.2
2023-08-26 12:33:25,737:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2023-08-26 12:33:25,737:INFO:machine: AMD64
2023-08-26 12:33:25,737:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-26 12:33:25,741:INFO:Memory: svmem(total=12729561088, available=4288630784, percent=66.3, used=8440930304, free=4288630784)
2023-08-26 12:33:25,741:INFO:Physical Core: 2
2023-08-26 12:33:25,742:INFO:Logical Core: 4
2023-08-26 12:33:25,742:INFO:Checking libraries
2023-08-26 12:33:25,742:INFO:System:
2023-08-26 12:33:25,742:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2023-08-26 12:33:25,743:INFO:executable: c:\Users\Gabi\Documents\GitHub\superstore\venv\Scripts\python.exe
2023-08-26 12:33:25,743:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-26 12:33:25,743:INFO:PyCaret required dependencies:
2023-08-26 12:33:25,807:INFO:                 pip: 23.2.1
2023-08-26 12:33:25,808:INFO:          setuptools: 58.1.0
2023-08-26 12:33:25,808:INFO:             pycaret: 3.0.4
2023-08-26 12:33:25,808:INFO:             IPython: 8.14.0
2023-08-26 12:33:25,809:INFO:          ipywidgets: 8.1.0
2023-08-26 12:33:25,809:INFO:                tqdm: 4.66.1
2023-08-26 12:33:25,809:INFO:               numpy: 1.23.5
2023-08-26 12:33:25,809:INFO:              pandas: 1.5.3
2023-08-26 12:33:25,810:INFO:              jinja2: 3.1.2
2023-08-26 12:33:25,811:INFO:               scipy: 1.11.2
2023-08-26 12:33:25,811:INFO:              joblib: 1.3.2
2023-08-26 12:33:25,811:INFO:             sklearn: 1.2.2
2023-08-26 12:33:25,812:INFO:                pyod: 1.1.0
2023-08-26 12:33:25,812:INFO:            imblearn: 0.11.0
2023-08-26 12:33:25,812:INFO:   category_encoders: 2.6.2
2023-08-26 12:33:25,812:INFO:            lightgbm: 4.0.0
2023-08-26 12:33:25,813:INFO:               numba: 0.57.1
2023-08-26 12:33:25,813:INFO:            requests: 2.31.0
2023-08-26 12:33:25,813:INFO:          matplotlib: 3.7.2
2023-08-26 12:33:25,813:INFO:          scikitplot: 0.3.7
2023-08-26 12:33:25,813:INFO:         yellowbrick: 1.5
2023-08-26 12:33:25,814:INFO:              plotly: 5.16.1
2023-08-26 12:33:25,814:INFO:    plotly-resampler: Not installed
2023-08-26 12:33:25,814:INFO:             kaleido: 0.2.1
2023-08-26 12:33:25,814:INFO:           schemdraw: 0.15
2023-08-26 12:33:25,814:INFO:         statsmodels: 0.14.0
2023-08-26 12:33:25,814:INFO:              sktime: 0.22.0
2023-08-26 12:33:25,814:INFO:               tbats: 1.1.3
2023-08-26 12:33:25,814:INFO:            pmdarima: 2.0.3
2023-08-26 12:33:25,815:INFO:              psutil: 5.9.5
2023-08-26 12:33:25,815:INFO:          markupsafe: 2.1.3
2023-08-26 12:33:25,815:INFO:             pickle5: Not installed
2023-08-26 12:33:25,815:INFO:         cloudpickle: 2.2.1
2023-08-26 12:33:25,815:INFO:         deprecation: 2.1.0
2023-08-26 12:33:25,815:INFO:              xxhash: 3.3.0
2023-08-26 12:33:25,815:INFO:           wurlitzer: Not installed
2023-08-26 12:33:25,815:INFO:PyCaret optional dependencies:
2023-08-26 12:33:25,870:INFO:                shap: Not installed
2023-08-26 12:33:25,870:INFO:           interpret: Not installed
2023-08-26 12:33:25,871:INFO:                umap: Not installed
2023-08-26 12:33:25,871:INFO:    pandas_profiling: Not installed
2023-08-26 12:33:25,871:INFO:  explainerdashboard: Not installed
2023-08-26 12:33:25,871:INFO:             autoviz: Not installed
2023-08-26 12:33:25,871:INFO:           fairlearn: Not installed
2023-08-26 12:33:25,871:INFO:          deepchecks: Not installed
2023-08-26 12:33:25,871:INFO:             xgboost: 1.7.6
2023-08-26 12:33:25,872:INFO:            catboost: Not installed
2023-08-26 12:33:25,872:INFO:              kmodes: Not installed
2023-08-26 12:33:25,872:INFO:             mlxtend: Not installed
2023-08-26 12:33:25,872:INFO:       statsforecast: Not installed
2023-08-26 12:33:25,872:INFO:        tune_sklearn: Not installed
2023-08-26 12:33:25,872:INFO:                 ray: Not installed
2023-08-26 12:33:25,872:INFO:            hyperopt: Not installed
2023-08-26 12:33:25,873:INFO:              optuna: Not installed
2023-08-26 12:33:25,873:INFO:               skopt: Not installed
2023-08-26 12:33:25,873:INFO:              mlflow: Not installed
2023-08-26 12:33:25,873:INFO:              gradio: Not installed
2023-08-26 12:33:25,873:INFO:             fastapi: Not installed
2023-08-26 12:33:25,873:INFO:             uvicorn: Not installed
2023-08-26 12:33:25,873:INFO:              m2cgen: Not installed
2023-08-26 12:33:25,873:INFO:           evidently: Not installed
2023-08-26 12:33:25,874:INFO:               fugue: Not installed
2023-08-26 12:33:25,874:INFO:           streamlit: Not installed
2023-08-26 12:33:25,874:INFO:             prophet: Not installed
2023-08-26 12:33:25,874:INFO:None
2023-08-26 12:33:25,874:INFO:Set up data.
2023-08-26 12:33:25,913:INFO:Set up train/test split.
2023-08-26 12:33:25,933:INFO:Set up index.
2023-08-26 12:33:25,934:INFO:Set up folding strategy.
2023-08-26 12:33:25,934:INFO:Assigning column types.
2023-08-26 12:33:25,948:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-26 12:33:26,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:33:26,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:33:26,282:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:26,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:26,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-26 12:33:26,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:33:26,668:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:26,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:26,681:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-26 12:33:26,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:33:27,002:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:27,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:27,187:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-26 12:33:27,289:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:27,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:27,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-26 12:33:27,569:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:27,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:28,032:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:28,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:28,053:INFO:Preparing preprocessing pipeline...
2023-08-26 12:33:28,056:INFO:Set up simple imputation.
2023-08-26 12:33:28,065:INFO:Set up encoding of categorical features.
2023-08-26 12:33:28,309:INFO:Finished creating preprocessing pipeline.
2023-08-26 12:33:28,329:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Gabi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'Year_Birth', 'Income',
                                             'Kidhome', 'Teenhome', 'Recency',
                                             'MntWines', 'MntFruits',
                                             'MntMeatProducts',
                                             'MntFishProducts',
                                             'MntSweetProducts', 'MntGoldProds',
                                             'NumDealsPurchases',
                                             'NumWebPurchases',
                                             'NumCatalogPurc...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Dt_Customer'],
                                    transformer=TargetEncoder(cols=['Dt_Customer'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-08-26 12:33:28,329:INFO:Creating final display dataframe.
2023-08-26 12:33:28,637:INFO:Setup _display_container:                     Description             Value
0                    Session id             10001
1                        Target          Response
2                   Target type            Binary
3           Original data shape        (2128, 22)
4        Transformed data shape        (2128, 32)
5   Transformed train set shape        (1489, 32)
6    Transformed test set shape         (639, 32)
7              Numeric features                18
8          Categorical features                 3
9      Rows with missing values              1.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              004b
2023-08-26 12:33:29,004:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:29,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:29,294:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:33:29,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:33:29,305:INFO:setup() successfully completed in 4.2s...............
2023-08-26 12:33:29,391:INFO:Initializing compare_models()
2023-08-26 12:33:29,391:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-26 12:33:29,392:INFO:Checking exceptions
2023-08-26 12:33:29,404:INFO:Preparing display monitor
2023-08-26 12:33:29,470:INFO:Initializing Logistic Regression
2023-08-26 12:33:29,470:INFO:Total runtime is 0.0 minutes
2023-08-26 12:33:29,479:INFO:SubProcess create_model() called ==================================
2023-08-26 12:33:29,480:INFO:Initializing create_model()
2023-08-26 12:33:29,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:33:29,480:INFO:Checking exceptions
2023-08-26 12:33:29,481:INFO:Importing libraries
2023-08-26 12:33:29,481:INFO:Copying training dataset
2023-08-26 12:33:29,498:INFO:Defining folds
2023-08-26 12:33:29,504:INFO:Declaring metric variables
2023-08-26 12:33:29,520:INFO:Importing untrained model
2023-08-26 12:33:29,669:INFO:Logistic Regression Imported successfully
2023-08-26 12:33:29,688:INFO:Starting cross validation
2023-08-26 12:33:29,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:33:48,251:INFO:Calculating mean and std
2023-08-26 12:33:48,257:INFO:Creating metrics dataframe
2023-08-26 12:33:48,831:INFO:Uploading results into container
2023-08-26 12:33:48,834:INFO:Uploading model into container now
2023-08-26 12:33:48,836:INFO:_master_model_container: 1
2023-08-26 12:33:48,836:INFO:_display_container: 2
2023-08-26 12:33:48,837:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:33:48,838:INFO:create_model() successfully completed......................................
2023-08-26 12:33:48,926:INFO:SubProcess create_model() end ==================================
2023-08-26 12:33:48,926:INFO:Creating metrics dataframe
2023-08-26 12:33:48,944:INFO:Initializing K Neighbors Classifier
2023-08-26 12:33:48,945:INFO:Total runtime is 0.32458272377649944 minutes
2023-08-26 12:33:48,953:INFO:SubProcess create_model() called ==================================
2023-08-26 12:33:48,954:INFO:Initializing create_model()
2023-08-26 12:33:48,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:33:48,955:INFO:Checking exceptions
2023-08-26 12:33:48,955:INFO:Importing libraries
2023-08-26 12:33:48,955:INFO:Copying training dataset
2023-08-26 12:33:48,969:INFO:Defining folds
2023-08-26 12:33:48,969:INFO:Declaring metric variables
2023-08-26 12:33:48,978:INFO:Importing untrained model
2023-08-26 12:33:48,992:INFO:K Neighbors Classifier Imported successfully
2023-08-26 12:33:49,017:INFO:Starting cross validation
2023-08-26 12:33:49,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:33:57,350:INFO:Calculating mean and std
2023-08-26 12:33:57,353:INFO:Creating metrics dataframe
2023-08-26 12:33:58,037:INFO:Uploading results into container
2023-08-26 12:33:58,039:INFO:Uploading model into container now
2023-08-26 12:33:58,041:INFO:_master_model_container: 2
2023-08-26 12:33:58,041:INFO:_display_container: 2
2023-08-26 12:33:58,043:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-26 12:33:58,044:INFO:create_model() successfully completed......................................
2023-08-26 12:33:58,131:INFO:SubProcess create_model() end ==================================
2023-08-26 12:33:58,132:INFO:Creating metrics dataframe
2023-08-26 12:33:58,153:INFO:Initializing Naive Bayes
2023-08-26 12:33:58,153:INFO:Total runtime is 0.4780504266421 minutes
2023-08-26 12:33:58,163:INFO:SubProcess create_model() called ==================================
2023-08-26 12:33:58,164:INFO:Initializing create_model()
2023-08-26 12:33:58,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:33:58,164:INFO:Checking exceptions
2023-08-26 12:33:58,164:INFO:Importing libraries
2023-08-26 12:33:58,165:INFO:Copying training dataset
2023-08-26 12:33:58,177:INFO:Defining folds
2023-08-26 12:33:58,178:INFO:Declaring metric variables
2023-08-26 12:33:58,187:INFO:Importing untrained model
2023-08-26 12:33:58,196:INFO:Naive Bayes Imported successfully
2023-08-26 12:33:58,211:INFO:Starting cross validation
2023-08-26 12:33:58,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:05,691:INFO:Calculating mean and std
2023-08-26 12:34:05,694:INFO:Creating metrics dataframe
2023-08-26 12:34:06,249:INFO:Uploading results into container
2023-08-26 12:34:06,251:INFO:Uploading model into container now
2023-08-26 12:34:06,253:INFO:_master_model_container: 3
2023-08-26 12:34:06,253:INFO:_display_container: 2
2023-08-26 12:34:06,254:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-26 12:34:06,255:INFO:create_model() successfully completed......................................
2023-08-26 12:34:06,348:INFO:SubProcess create_model() end ==================================
2023-08-26 12:34:06,349:INFO:Creating metrics dataframe
2023-08-26 12:34:06,379:INFO:Initializing Decision Tree Classifier
2023-08-26 12:34:06,380:INFO:Total runtime is 0.6151657223701477 minutes
2023-08-26 12:34:06,393:INFO:SubProcess create_model() called ==================================
2023-08-26 12:34:06,394:INFO:Initializing create_model()
2023-08-26 12:34:06,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:34:06,395:INFO:Checking exceptions
2023-08-26 12:34:06,395:INFO:Importing libraries
2023-08-26 12:34:06,395:INFO:Copying training dataset
2023-08-26 12:34:06,415:INFO:Defining folds
2023-08-26 12:34:06,415:INFO:Declaring metric variables
2023-08-26 12:34:06,434:INFO:Importing untrained model
2023-08-26 12:34:06,446:INFO:Decision Tree Classifier Imported successfully
2023-08-26 12:34:06,471:INFO:Starting cross validation
2023-08-26 12:34:06,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:15,386:INFO:Calculating mean and std
2023-08-26 12:34:15,389:INFO:Creating metrics dataframe
2023-08-26 12:34:15,984:INFO:Uploading results into container
2023-08-26 12:34:15,986:INFO:Uploading model into container now
2023-08-26 12:34:15,987:INFO:_master_model_container: 4
2023-08-26 12:34:15,987:INFO:_display_container: 2
2023-08-26 12:34:15,988:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=10001, splitter='best')
2023-08-26 12:34:15,989:INFO:create_model() successfully completed......................................
2023-08-26 12:34:16,082:INFO:SubProcess create_model() end ==================================
2023-08-26 12:34:16,082:INFO:Creating metrics dataframe
2023-08-26 12:34:16,104:INFO:Initializing SVM - Linear Kernel
2023-08-26 12:34:16,104:INFO:Total runtime is 0.7772369782129923 minutes
2023-08-26 12:34:16,113:INFO:SubProcess create_model() called ==================================
2023-08-26 12:34:16,114:INFO:Initializing create_model()
2023-08-26 12:34:16,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:34:16,114:INFO:Checking exceptions
2023-08-26 12:34:16,115:INFO:Importing libraries
2023-08-26 12:34:16,115:INFO:Copying training dataset
2023-08-26 12:34:16,128:INFO:Defining folds
2023-08-26 12:34:16,129:INFO:Declaring metric variables
2023-08-26 12:34:16,137:INFO:Importing untrained model
2023-08-26 12:34:16,147:INFO:SVM - Linear Kernel Imported successfully
2023-08-26 12:34:16,161:INFO:Starting cross validation
2023-08-26 12:34:16,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:16,717:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:16,734:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:17,776:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:17,801:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:17,833:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:17,865:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:17,871:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:17,894:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:34:17,923:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:18,723:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:18,740:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:18,790:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:20,644:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:20,662:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:20,780:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:20,791:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:20,792:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:20,838:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:22,483:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:34:23,071:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:24,857:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:34:25,091:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:34:26,563:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.94s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:34:26,748:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:34:27,618:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:34:27,764:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:27,775:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:28,339:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-26 12:34:28,356:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:34:31,130:INFO:Calculating mean and std
2023-08-26 12:34:31,134:INFO:Creating metrics dataframe
2023-08-26 12:34:32,002:INFO:Uploading results into container
2023-08-26 12:34:32,004:INFO:Uploading model into container now
2023-08-26 12:34:32,005:INFO:_master_model_container: 5
2023-08-26 12:34:32,006:INFO:_display_container: 2
2023-08-26 12:34:32,009:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=10001, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-26 12:34:32,009:INFO:create_model() successfully completed......................................
2023-08-26 12:34:32,101:INFO:SubProcess create_model() end ==================================
2023-08-26 12:34:32,101:INFO:Creating metrics dataframe
2023-08-26 12:34:32,124:INFO:Initializing Ridge Classifier
2023-08-26 12:34:32,125:INFO:Total runtime is 1.0442558169364928 minutes
2023-08-26 12:34:32,135:INFO:SubProcess create_model() called ==================================
2023-08-26 12:34:32,135:INFO:Initializing create_model()
2023-08-26 12:34:32,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:34:32,136:INFO:Checking exceptions
2023-08-26 12:34:32,136:INFO:Importing libraries
2023-08-26 12:34:32,136:INFO:Copying training dataset
2023-08-26 12:34:32,150:INFO:Defining folds
2023-08-26 12:34:32,150:INFO:Declaring metric variables
2023-08-26 12:34:32,159:INFO:Importing untrained model
2023-08-26 12:34:32,169:INFO:Ridge Classifier Imported successfully
2023-08-26 12:34:32,185:INFO:Starting cross validation
2023-08-26 12:34:32,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:33,031:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:33,069:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:34,474:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:34,634:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:35,396:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:35,553:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:36,827:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:36,863:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:38,145:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:38,650:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-26 12:34:41,970:INFO:Calculating mean and std
2023-08-26 12:34:41,975:INFO:Creating metrics dataframe
2023-08-26 12:34:42,645:INFO:Uploading results into container
2023-08-26 12:34:42,647:INFO:Uploading model into container now
2023-08-26 12:34:42,650:INFO:_master_model_container: 6
2023-08-26 12:34:42,650:INFO:_display_container: 2
2023-08-26 12:34:42,651:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=10001,
                solver='auto', tol=0.0001)
2023-08-26 12:34:42,651:INFO:create_model() successfully completed......................................
2023-08-26 12:34:42,748:INFO:SubProcess create_model() end ==================================
2023-08-26 12:34:42,749:INFO:Creating metrics dataframe
2023-08-26 12:34:42,777:INFO:Initializing Random Forest Classifier
2023-08-26 12:34:42,778:INFO:Total runtime is 1.2218014121055603 minutes
2023-08-26 12:34:42,789:INFO:SubProcess create_model() called ==================================
2023-08-26 12:34:42,790:INFO:Initializing create_model()
2023-08-26 12:34:42,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:34:42,791:INFO:Checking exceptions
2023-08-26 12:34:42,791:INFO:Importing libraries
2023-08-26 12:34:42,792:INFO:Copying training dataset
2023-08-26 12:34:42,807:INFO:Defining folds
2023-08-26 12:34:42,808:INFO:Declaring metric variables
2023-08-26 12:34:42,831:INFO:Importing untrained model
2023-08-26 12:34:42,845:INFO:Random Forest Classifier Imported successfully
2023-08-26 12:34:42,872:INFO:Starting cross validation
2023-08-26 12:34:42,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:45,707:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:45,836:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:49,084:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:34:50,195:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:34:57,202:INFO:Calculating mean and std
2023-08-26 12:34:57,205:INFO:Creating metrics dataframe
2023-08-26 12:34:57,864:INFO:Uploading results into container
2023-08-26 12:34:57,866:INFO:Uploading model into container now
2023-08-26 12:34:57,867:INFO:_master_model_container: 7
2023-08-26 12:34:57,868:INFO:_display_container: 2
2023-08-26 12:34:57,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=10001, verbose=0, warm_start=False)
2023-08-26 12:34:57,870:INFO:create_model() successfully completed......................................
2023-08-26 12:34:57,966:INFO:SubProcess create_model() end ==================================
2023-08-26 12:34:57,966:INFO:Creating metrics dataframe
2023-08-26 12:34:57,990:INFO:Initializing Quadratic Discriminant Analysis
2023-08-26 12:34:57,990:INFO:Total runtime is 1.4753446936607362 minutes
2023-08-26 12:34:57,999:INFO:SubProcess create_model() called ==================================
2023-08-26 12:34:58,000:INFO:Initializing create_model()
2023-08-26 12:34:58,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:34:58,000:INFO:Checking exceptions
2023-08-26 12:34:58,001:INFO:Importing libraries
2023-08-26 12:34:58,001:INFO:Copying training dataset
2023-08-26 12:34:58,012:INFO:Defining folds
2023-08-26 12:34:58,012:INFO:Declaring metric variables
2023-08-26 12:34:58,025:INFO:Importing untrained model
2023-08-26 12:34:58,033:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-26 12:34:58,061:INFO:Starting cross validation
2023-08-26 12:34:58,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:34:58,485:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:34:58,489:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:34:58,512:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:34:58,511:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:34:59,545:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:34:59,752:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:35:00,937:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:00,980:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:01,335:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:35:01,817:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:01,931:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:03,228:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:03,237:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-26 12:35:03,544:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:35:03,561:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:35:07,210:INFO:Calculating mean and std
2023-08-26 12:35:07,214:INFO:Creating metrics dataframe
2023-08-26 12:35:07,889:INFO:Uploading results into container
2023-08-26 12:35:07,891:INFO:Uploading model into container now
2023-08-26 12:35:07,892:INFO:_master_model_container: 8
2023-08-26 12:35:07,893:INFO:_display_container: 2
2023-08-26 12:35:07,894:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-26 12:35:07,895:INFO:create_model() successfully completed......................................
2023-08-26 12:35:07,997:INFO:SubProcess create_model() end ==================================
2023-08-26 12:35:07,997:INFO:Creating metrics dataframe
2023-08-26 12:35:08,025:INFO:Initializing Ada Boost Classifier
2023-08-26 12:35:08,026:INFO:Total runtime is 1.6426080147425335 minutes
2023-08-26 12:35:08,034:INFO:SubProcess create_model() called ==================================
2023-08-26 12:35:08,034:INFO:Initializing create_model()
2023-08-26 12:35:08,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:35:08,035:INFO:Checking exceptions
2023-08-26 12:35:08,035:INFO:Importing libraries
2023-08-26 12:35:08,035:INFO:Copying training dataset
2023-08-26 12:35:08,047:INFO:Defining folds
2023-08-26 12:35:08,047:INFO:Declaring metric variables
2023-08-26 12:35:08,059:INFO:Importing untrained model
2023-08-26 12:35:08,070:INFO:Ada Boost Classifier Imported successfully
2023-08-26 12:35:08,098:INFO:Starting cross validation
2023-08-26 12:35:08,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:35:09,544:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:35:21,348:INFO:Calculating mean and std
2023-08-26 12:35:21,351:INFO:Creating metrics dataframe
2023-08-26 12:35:22,015:INFO:Uploading results into container
2023-08-26 12:35:22,018:INFO:Uploading model into container now
2023-08-26 12:35:22,020:INFO:_master_model_container: 9
2023-08-26 12:35:22,020:INFO:_display_container: 2
2023-08-26 12:35:22,021:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=10001)
2023-08-26 12:35:22,021:INFO:create_model() successfully completed......................................
2023-08-26 12:35:22,116:INFO:SubProcess create_model() end ==================================
2023-08-26 12:35:22,116:INFO:Creating metrics dataframe
2023-08-26 12:35:22,144:INFO:Initializing Gradient Boosting Classifier
2023-08-26 12:35:22,144:INFO:Total runtime is 1.8779046177864076 minutes
2023-08-26 12:35:22,157:INFO:SubProcess create_model() called ==================================
2023-08-26 12:35:22,157:INFO:Initializing create_model()
2023-08-26 12:35:22,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:35:22,158:INFO:Checking exceptions
2023-08-26 12:35:22,159:INFO:Importing libraries
2023-08-26 12:35:22,159:INFO:Copying training dataset
2023-08-26 12:35:22,191:INFO:Defining folds
2023-08-26 12:35:22,191:INFO:Declaring metric variables
2023-08-26 12:35:22,210:INFO:Importing untrained model
2023-08-26 12:35:22,229:INFO:Gradient Boosting Classifier Imported successfully
2023-08-26 12:35:22,256:INFO:Starting cross validation
2023-08-26 12:35:22,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:35:38,411:INFO:Calculating mean and std
2023-08-26 12:35:38,418:INFO:Creating metrics dataframe
2023-08-26 12:35:39,815:INFO:Uploading results into container
2023-08-26 12:35:39,820:INFO:Uploading model into container now
2023-08-26 12:35:39,821:INFO:_master_model_container: 10
2023-08-26 12:35:39,821:INFO:_display_container: 2
2023-08-26 12:35:39,823:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=10001, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-26 12:35:39,823:INFO:create_model() successfully completed......................................
2023-08-26 12:35:40,043:INFO:SubProcess create_model() end ==================================
2023-08-26 12:35:40,044:INFO:Creating metrics dataframe
2023-08-26 12:35:40,116:INFO:Initializing Linear Discriminant Analysis
2023-08-26 12:35:40,119:INFO:Total runtime is 2.1774862170219422 minutes
2023-08-26 12:35:40,135:INFO:SubProcess create_model() called ==================================
2023-08-26 12:35:40,136:INFO:Initializing create_model()
2023-08-26 12:35:40,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:35:40,137:INFO:Checking exceptions
2023-08-26 12:35:40,138:INFO:Importing libraries
2023-08-26 12:35:40,138:INFO:Copying training dataset
2023-08-26 12:35:40,204:INFO:Defining folds
2023-08-26 12:35:40,204:INFO:Declaring metric variables
2023-08-26 12:35:40,229:INFO:Importing untrained model
2023-08-26 12:35:40,258:INFO:Linear Discriminant Analysis Imported successfully
2023-08-26 12:35:40,406:INFO:Starting cross validation
2023-08-26 12:35:40,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:35:45,712:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:45,716:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:46,182:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:46,426:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:47,069:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.97s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:35:47,344:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:48,679:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.18s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:48,872:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.07s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:49,346:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:35:49,595:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:35:50,554:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:35:50,899:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:35:51,864:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:36:02,940:INFO:Calculating mean and std
2023-08-26 12:36:02,945:INFO:Creating metrics dataframe
2023-08-26 12:36:04,324:INFO:Uploading results into container
2023-08-26 12:36:04,326:INFO:Uploading model into container now
2023-08-26 12:36:04,332:INFO:_master_model_container: 11
2023-08-26 12:36:04,332:INFO:_display_container: 2
2023-08-26 12:36:04,345:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-26 12:36:04,346:INFO:create_model() successfully completed......................................
2023-08-26 12:36:04,571:INFO:SubProcess create_model() end ==================================
2023-08-26 12:36:04,572:INFO:Creating metrics dataframe
2023-08-26 12:36:04,612:INFO:Initializing Extra Trees Classifier
2023-08-26 12:36:04,612:INFO:Total runtime is 2.5857012033462525 minutes
2023-08-26 12:36:04,625:INFO:SubProcess create_model() called ==================================
2023-08-26 12:36:04,626:INFO:Initializing create_model()
2023-08-26 12:36:04,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:36:04,627:INFO:Checking exceptions
2023-08-26 12:36:04,627:INFO:Importing libraries
2023-08-26 12:36:04,627:INFO:Copying training dataset
2023-08-26 12:36:04,663:INFO:Defining folds
2023-08-26 12:36:04,664:INFO:Declaring metric variables
2023-08-26 12:36:04,681:INFO:Importing untrained model
2023-08-26 12:36:04,748:INFO:Extra Trees Classifier Imported successfully
2023-08-26 12:36:04,775:INFO:Starting cross validation
2023-08-26 12:36:04,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:36:23,061:INFO:Calculating mean and std
2023-08-26 12:36:23,064:INFO:Creating metrics dataframe
2023-08-26 12:36:23,859:INFO:Uploading results into container
2023-08-26 12:36:23,861:INFO:Uploading model into container now
2023-08-26 12:36:23,862:INFO:_master_model_container: 12
2023-08-26 12:36:23,863:INFO:_display_container: 2
2023-08-26 12:36:23,865:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=10001, verbose=0, warm_start=False)
2023-08-26 12:36:23,866:INFO:create_model() successfully completed......................................
2023-08-26 12:36:23,999:INFO:SubProcess create_model() end ==================================
2023-08-26 12:36:23,999:INFO:Creating metrics dataframe
2023-08-26 12:36:24,057:INFO:Initializing Extreme Gradient Boosting
2023-08-26 12:36:24,057:INFO:Total runtime is 2.9097850640614826 minutes
2023-08-26 12:36:24,070:INFO:SubProcess create_model() called ==================================
2023-08-26 12:36:24,071:INFO:Initializing create_model()
2023-08-26 12:36:24,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:36:24,071:INFO:Checking exceptions
2023-08-26 12:36:24,071:INFO:Importing libraries
2023-08-26 12:36:24,072:INFO:Copying training dataset
2023-08-26 12:36:24,091:INFO:Defining folds
2023-08-26 12:36:24,091:INFO:Declaring metric variables
2023-08-26 12:36:24,105:INFO:Importing untrained model
2023-08-26 12:36:24,119:INFO:Extreme Gradient Boosting Imported successfully
2023-08-26 12:36:24,160:INFO:Starting cross validation
2023-08-26 12:36:24,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:36:43,992:INFO:Calculating mean and std
2023-08-26 12:36:43,998:INFO:Creating metrics dataframe
2023-08-26 12:36:47,684:INFO:Uploading results into container
2023-08-26 12:36:47,718:INFO:Uploading model into container now
2023-08-26 12:36:47,723:INFO:_master_model_container: 13
2023-08-26 12:36:47,723:INFO:_display_container: 2
2023-08-26 12:36:47,728:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-26 12:36:47,728:INFO:create_model() successfully completed......................................
2023-08-26 12:36:48,104:INFO:SubProcess create_model() end ==================================
2023-08-26 12:36:48,105:INFO:Creating metrics dataframe
2023-08-26 12:36:48,277:INFO:Initializing Light Gradient Boosting Machine
2023-08-26 12:36:48,277:INFO:Total runtime is 3.313461605707804 minutes
2023-08-26 12:36:48,298:INFO:SubProcess create_model() called ==================================
2023-08-26 12:36:48,300:INFO:Initializing create_model()
2023-08-26 12:36:48,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:36:48,302:INFO:Checking exceptions
2023-08-26 12:36:48,303:INFO:Importing libraries
2023-08-26 12:36:48,303:INFO:Copying training dataset
2023-08-26 12:36:48,376:INFO:Defining folds
2023-08-26 12:36:48,377:INFO:Declaring metric variables
2023-08-26 12:36:48,444:INFO:Importing untrained model
2023-08-26 12:36:48,468:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-26 12:36:48,595:INFO:Starting cross validation
2023-08-26 12:36:48,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:36:50,257:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:36:50,273:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.95s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:36:50,323:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:36:51,191:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.08s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:36:51,556:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:36:51,807:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:36:51,934:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.94s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:36:52,991:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:36:54,139:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:36:54,232:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.30s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:36:55,191:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:37:10,462:INFO:Calculating mean and std
2023-08-26 12:37:10,468:INFO:Creating metrics dataframe
2023-08-26 12:37:11,760:INFO:Uploading results into container
2023-08-26 12:37:11,764:INFO:Uploading model into container now
2023-08-26 12:37:11,768:INFO:_master_model_container: 14
2023-08-26 12:37:11,769:INFO:_display_container: 2
2023-08-26 12:37:11,774:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=10001, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-26 12:37:11,775:INFO:create_model() successfully completed......................................
2023-08-26 12:37:12,007:INFO:SubProcess create_model() end ==================================
2023-08-26 12:37:12,007:INFO:Creating metrics dataframe
2023-08-26 12:37:12,129:INFO:Initializing Dummy Classifier
2023-08-26 12:37:12,129:INFO:Total runtime is 3.7109826525052387 minutes
2023-08-26 12:37:12,149:INFO:SubProcess create_model() called ==================================
2023-08-26 12:37:12,150:INFO:Initializing create_model()
2023-08-26 12:37:12,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240BF282DA0>, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:37:12,152:INFO:Checking exceptions
2023-08-26 12:37:12,152:INFO:Importing libraries
2023-08-26 12:37:12,152:INFO:Copying training dataset
2023-08-26 12:37:12,185:INFO:Defining folds
2023-08-26 12:37:12,185:INFO:Declaring metric variables
2023-08-26 12:37:12,206:INFO:Importing untrained model
2023-08-26 12:37:12,227:INFO:Dummy Classifier Imported successfully
2023-08-26 12:37:12,307:INFO:Starting cross validation
2023-08-26 12:37:12,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:37:14,458:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:14,559:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:14,652:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:14,949:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.24s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:37:15,866:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:19,670:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:19,690:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:19,838:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:20,434:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:22,649:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:22,716:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-26 12:37:33,592:INFO:Calculating mean and std
2023-08-26 12:37:33,600:INFO:Creating metrics dataframe
2023-08-26 12:37:35,897:INFO:Uploading results into container
2023-08-26 12:37:35,921:INFO:Uploading model into container now
2023-08-26 12:37:35,925:INFO:_master_model_container: 15
2023-08-26 12:37:35,926:INFO:_display_container: 2
2023-08-26 12:37:35,927:INFO:DummyClassifier(constant=None, random_state=10001, strategy='prior')
2023-08-26 12:37:35,927:INFO:create_model() successfully completed......................................
2023-08-26 12:37:36,154:INFO:SubProcess create_model() end ==================================
2023-08-26 12:37:36,155:INFO:Creating metrics dataframe
2023-08-26 12:37:36,417:INFO:Initializing create_model()
2023-08-26 12:37:36,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:37:36,420:INFO:Checking exceptions
2023-08-26 12:37:36,432:INFO:Importing libraries
2023-08-26 12:37:36,432:INFO:Copying training dataset
2023-08-26 12:37:36,477:INFO:Defining folds
2023-08-26 12:37:36,478:INFO:Declaring metric variables
2023-08-26 12:37:36,479:INFO:Importing untrained model
2023-08-26 12:37:36,479:INFO:Declaring custom model
2023-08-26 12:37:36,483:INFO:Logistic Regression Imported successfully
2023-08-26 12:37:36,494:INFO:Cross validation set to False
2023-08-26 12:37:36,495:INFO:Fitting Model
2023-08-26 12:37:41,402:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:37:41,403:INFO:create_model() successfully completed......................................
2023-08-26 12:37:41,873:INFO:_master_model_container: 15
2023-08-26 12:37:41,877:INFO:_display_container: 2
2023-08-26 12:37:41,879:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:37:41,879:INFO:compare_models() successfully completed......................................
2023-08-26 12:37:43,392:INFO:gpu_param set to False
2023-08-26 12:37:43,951:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:37:43,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:37:44,427:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-26 12:37:44,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-26 12:37:44,616:INFO:Initializing create_model()
2023-08-26 12:37:44,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:37:44,617:INFO:Checking exceptions
2023-08-26 12:37:44,669:INFO:Importing libraries
2023-08-26 12:37:44,670:INFO:Copying training dataset
2023-08-26 12:37:44,690:INFO:Defining folds
2023-08-26 12:37:44,690:INFO:Declaring metric variables
2023-08-26 12:37:44,705:INFO:Importing untrained model
2023-08-26 12:37:44,718:INFO:Naive Bayes Imported successfully
2023-08-26 12:37:44,743:INFO:Starting cross validation
2023-08-26 12:37:44,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:37:59,695:INFO:Calculating mean and std
2023-08-26 12:37:59,698:INFO:Creating metrics dataframe
2023-08-26 12:37:59,717:INFO:Finalizing model
2023-08-26 12:38:00,952:INFO:Uploading results into container
2023-08-26 12:38:00,954:INFO:Uploading model into container now
2023-08-26 12:38:00,983:INFO:_master_model_container: 16
2023-08-26 12:38:00,983:INFO:_display_container: 3
2023-08-26 12:38:00,984:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-26 12:38:00,985:INFO:create_model() successfully completed......................................
2023-08-26 12:38:01,220:INFO:Initializing create_model()
2023-08-26 12:38:01,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:38:01,220:INFO:Checking exceptions
2023-08-26 12:38:01,274:INFO:Importing libraries
2023-08-26 12:38:01,274:INFO:Copying training dataset
2023-08-26 12:38:01,294:INFO:Defining folds
2023-08-26 12:38:01,295:INFO:Declaring metric variables
2023-08-26 12:38:01,309:INFO:Importing untrained model
2023-08-26 12:38:01,321:INFO:Logistic Regression Imported successfully
2023-08-26 12:38:01,349:INFO:Starting cross validation
2023-08-26 12:38:01,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:38:02,507:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:38:17,096:INFO:Calculating mean and std
2023-08-26 12:38:17,102:INFO:Creating metrics dataframe
2023-08-26 12:38:17,121:INFO:Finalizing model
2023-08-26 12:38:18,485:INFO:Uploading results into container
2023-08-26 12:38:18,487:INFO:Uploading model into container now
2023-08-26 12:38:18,515:INFO:_master_model_container: 17
2023-08-26 12:38:18,516:INFO:_display_container: 4
2023-08-26 12:38:18,517:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:38:18,517:INFO:create_model() successfully completed......................................
2023-08-26 12:38:18,717:INFO:Initializing create_model()
2023-08-26 12:38:18,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:38:18,717:INFO:Checking exceptions
2023-08-26 12:38:18,754:INFO:Importing libraries
2023-08-26 12:38:18,755:INFO:Copying training dataset
2023-08-26 12:38:18,778:INFO:Defining folds
2023-08-26 12:38:18,778:INFO:Declaring metric variables
2023-08-26 12:38:18,788:INFO:Importing untrained model
2023-08-26 12:38:18,801:INFO:Gradient Boosting Classifier Imported successfully
2023-08-26 12:38:18,829:INFO:Starting cross validation
2023-08-26 12:38:18,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:38:24,409:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:38:25,177:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-08-26 12:38:35,682:INFO:Calculating mean and std
2023-08-26 12:38:35,685:INFO:Creating metrics dataframe
2023-08-26 12:38:35,709:INFO:Finalizing model
2023-08-26 12:38:36,652:INFO:Uploading results into container
2023-08-26 12:38:36,654:INFO:Uploading model into container now
2023-08-26 12:38:36,680:INFO:_master_model_container: 18
2023-08-26 12:38:36,681:INFO:_display_container: 5
2023-08-26 12:38:36,682:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=10001, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-26 12:38:36,683:INFO:create_model() successfully completed......................................
2023-08-26 12:38:37,295:INFO:Initializing create_model()
2023-08-26 12:38:37,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:38:37,296:INFO:Checking exceptions
2023-08-26 12:38:37,334:INFO:Importing libraries
2023-08-26 12:38:37,334:INFO:Copying training dataset
2023-08-26 12:38:37,352:INFO:Defining folds
2023-08-26 12:38:37,353:INFO:Declaring metric variables
2023-08-26 12:38:37,361:INFO:Importing untrained model
2023-08-26 12:38:37,369:INFO:K Neighbors Classifier Imported successfully
2023-08-26 12:38:37,384:INFO:Starting cross validation
2023-08-26 12:38:37,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:38:51,142:INFO:Calculating mean and std
2023-08-26 12:38:51,145:INFO:Creating metrics dataframe
2023-08-26 12:38:51,161:INFO:Finalizing model
2023-08-26 12:38:52,070:INFO:Uploading results into container
2023-08-26 12:38:52,073:INFO:Uploading model into container now
2023-08-26 12:38:52,096:INFO:_master_model_container: 19
2023-08-26 12:38:52,096:INFO:_display_container: 6
2023-08-26 12:38:52,097:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-26 12:38:52,097:INFO:create_model() successfully completed......................................
2023-08-26 12:38:52,540:INFO:Initializing create_model()
2023-08-26 12:38:52,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:38:52,541:INFO:Checking exceptions
2023-08-26 12:38:52,599:INFO:Importing libraries
2023-08-26 12:38:52,599:INFO:Copying training dataset
2023-08-26 12:38:52,614:INFO:Defining folds
2023-08-26 12:38:52,615:INFO:Declaring metric variables
2023-08-26 12:38:52,638:INFO:Importing untrained model
2023-08-26 12:38:52,649:INFO:Random Forest Classifier Imported successfully
2023-08-26 12:38:52,695:INFO:Starting cross validation
2023-08-26 12:38:52,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:39:07,712:INFO:Calculating mean and std
2023-08-26 12:39:07,719:INFO:Creating metrics dataframe
2023-08-26 12:39:07,744:INFO:Finalizing model
2023-08-26 12:39:11,274:INFO:Uploading results into container
2023-08-26 12:39:11,278:INFO:Uploading model into container now
2023-08-26 12:39:11,315:INFO:_master_model_container: 20
2023-08-26 12:39:11,315:INFO:_display_container: 7
2023-08-26 12:39:11,317:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=10001, verbose=0, warm_start=False)
2023-08-26 12:39:11,318:INFO:create_model() successfully completed......................................
2023-08-26 12:40:37,488:INFO:Initializing tune_model()
2023-08-26 12:40:37,488:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>)
2023-08-26 12:40:37,488:INFO:Checking exceptions
2023-08-26 12:40:37,523:INFO:Copying training dataset
2023-08-26 12:40:37,535:INFO:Checking base model
2023-08-26 12:40:37,536:INFO:Base model : Logistic Regression
2023-08-26 12:40:37,543:INFO:Declaring metric variables
2023-08-26 12:40:37,551:INFO:Defining Hyperparameters
2023-08-26 12:40:37,674:INFO:Tuning with n_jobs=-1
2023-08-26 12:40:37,674:INFO:Initializing RandomizedSearchCV
2023-08-26 12:41:16,081:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:20,149:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:37,017:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.42s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:41:37,690:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:40,029:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:48,647:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:41:49,356:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:54,803:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:41:57,623:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:41:59,421:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:01,839:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:03,921:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:04,568:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:05,616:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:07,151:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:08,148:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:11,279:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:42:12,266:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:12,948:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:14,142:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:15,415:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:42:17,061:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:17,134:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:42:17,416:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:19,060:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:19,174:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:42:20,720:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:22,272:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:22,303:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:22,964:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:24,248:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:26,003:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:26,730:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:31,310:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:32,161:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:33,618:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:34,468:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:36,134:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:42:39,342:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:39,589:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:39,605:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-26 12:42:40,702:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:43,103:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:42:45,405:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.29s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:42:46,725:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:47,010:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:48,500:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:49,417:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:42:51,510:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:55,518:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:42:57,306:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:42:57,878:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:43:00,002:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:43:02,277:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:43:03,837:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:43:05,700:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:07,479:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:10,571:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:43:12,930:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.11s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:43:13,568:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:43:14,066:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:43:15,708:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:43:17,851:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:43:22,171:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:26,391:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:34,380:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-26 12:43:35,616:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:43:37,175:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:41,309:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:45,277:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:46,707:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:43:59,337:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.153}
2023-08-26 12:43:59,340:INFO:Hyperparameter search completed
2023-08-26 12:43:59,341:INFO:SubProcess create_model() called ==================================
2023-08-26 12:43:59,345:INFO:Initializing create_model()
2023-08-26 12:43:59,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240D2EEB640>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 7.153})
2023-08-26 12:43:59,346:INFO:Checking exceptions
2023-08-26 12:43:59,347:INFO:Importing libraries
2023-08-26 12:43:59,347:INFO:Copying training dataset
2023-08-26 12:43:59,367:INFO:Defining folds
2023-08-26 12:43:59,367:INFO:Declaring metric variables
2023-08-26 12:43:59,380:INFO:Importing untrained model
2023-08-26 12:43:59,380:INFO:Declaring custom model
2023-08-26 12:43:59,396:INFO:Logistic Regression Imported successfully
2023-08-26 12:43:59,421:INFO:Starting cross validation
2023-08-26 12:43:59,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:44:05,256:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-26 12:44:05,993:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:44:06,025:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:44:06,411:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-26 12:44:17,668:INFO:Calculating mean and std
2023-08-26 12:44:17,672:INFO:Creating metrics dataframe
2023-08-26 12:44:17,694:INFO:Finalizing model
2023-08-26 12:44:20,079:WARNING:c:\Users\Gabi\Documents\GitHub\superstore\venv\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-26 12:44:22,497:INFO:Uploading results into container
2023-08-26 12:44:22,502:INFO:Uploading model into container now
2023-08-26 12:44:22,505:INFO:_master_model_container: 21
2023-08-26 12:44:22,506:INFO:_display_container: 8
2023-08-26 12:44:22,537:INFO:LogisticRegression(C=7.153, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:44:22,538:INFO:create_model() successfully completed......................................
2023-08-26 12:44:22,777:INFO:SubProcess create_model() end ==================================
2023-08-26 12:44:22,778:INFO:choose_better activated
2023-08-26 12:44:22,799:INFO:SubProcess create_model() called ==================================
2023-08-26 12:44:22,804:INFO:Initializing create_model()
2023-08-26 12:44:22,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000240D2741930>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-26 12:44:22,807:INFO:Checking exceptions
2023-08-26 12:44:22,814:INFO:Importing libraries
2023-08-26 12:44:22,815:INFO:Copying training dataset
2023-08-26 12:44:22,879:INFO:Defining folds
2023-08-26 12:44:22,879:INFO:Declaring metric variables
2023-08-26 12:44:22,880:INFO:Importing untrained model
2023-08-26 12:44:22,885:INFO:Declaring custom model
2023-08-26 12:44:22,892:INFO:Logistic Regression Imported successfully
2023-08-26 12:44:22,895:INFO:Starting cross validation
2023-08-26 12:44:22,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-26 12:44:39,624:INFO:Calculating mean and std
2023-08-26 12:44:39,627:INFO:Creating metrics dataframe
2023-08-26 12:44:39,634:INFO:Finalizing model
2023-08-26 12:44:41,248:INFO:Uploading results into container
2023-08-26 12:44:41,250:INFO:Uploading model into container now
2023-08-26 12:44:41,251:INFO:_master_model_container: 22
2023-08-26 12:44:41,252:INFO:_display_container: 9
2023-08-26 12:44:41,253:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:44:41,253:INFO:create_model() successfully completed......................................
2023-08-26 12:44:41,381:INFO:SubProcess create_model() end ==================================
2023-08-26 12:44:41,382:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8496
2023-08-26 12:44:41,384:INFO:LogisticRegression(C=7.153, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8543
2023-08-26 12:44:41,386:INFO:LogisticRegression(C=7.153, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-08-26 12:44:41,386:INFO:choose_better completed
2023-08-26 12:44:41,420:INFO:_master_model_container: 22
2023-08-26 12:44:41,421:INFO:_display_container: 8
2023-08-26 12:44:41,422:INFO:LogisticRegression(C=7.153, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=10001, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-26 12:44:41,422:INFO:tune_model() successfully completed......................................
